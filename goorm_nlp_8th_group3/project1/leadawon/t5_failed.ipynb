{"cells":[{"cell_type":"markdown","metadata":{"id":"TH32rzgprvgM"},"source":["# Import requirements"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6785,"status":"ok","timestamp":1672209022734,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"G9EvC1HBuf41","outputId":"68abc60e-507b-4066-909e-d68794fe22af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AAdLxrUZrvgP","executionInfo":{"status":"ok","timestamp":1672209026032,"user_tz":-540,"elapsed":3310,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["import os\n","import pdb\n","import argparse\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from collections import defaultdict\n","\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","from transformers import (\n","    BertForSequenceClassification,\n","    BertTokenizer,\n","    AutoConfig,\n","    AdamW\n",")\n","\n","#new model\n","from transformers import (\n","    DistilBertTokenizer, \n","    DistilBertForSequenceClassification,\n","\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","\n","    T5Tokenizer, \n","    T5Model,\n","    T5ForConditionalGeneration,\n","    \n","    AutoModelWithLMHead,\n","\n","    AlbertTokenizer, \n","    AlbertModel,\n",")"]},{"cell_type":"markdown","metadata":{"id":"ASWOOmXqrvgQ"},"source":["# 1. Preprocess"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"RAnU6w29rvgR","executionInfo":{"status":"ok","timestamp":1672209026033,"user_tz":-540,"elapsed":14,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["def make_id_file(task, tokenizer):\n","    def make_data_strings(file_name):\n","        data_strings = []\n","        with open(os.path.join(file_name), 'r', encoding='utf-8') as f:\n","            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n","        for item in id_file_data:\n","            data_strings.append(' '.join([str(k) for k in item]))\n","        return data_strings\n","    \n","    print('it will take some times...')\n","    train_pos = make_data_strings('sentiment.train.1')\n","    train_neg = make_data_strings('sentiment.train.0')\n","    dev_pos = make_data_strings('sentiment.dev.1')\n","    dev_neg = make_data_strings('sentiment.dev.0')\n","\n","    print('make id file finished!')\n","    return train_pos, train_neg, dev_pos, dev_neg"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["641ba41e4d974d2490ec6fc1fbb1a5ac","7b58f32031b04fd295eb84bbd0de7873","73e05f6faeae45ce9f03d96d98a078e7","0275038dfbcf4451a07d0198de02eef3","3a7acf84b3cc4932bba93044ee4dc5f3","080cde53beb3423d8e600dc30226ef9d","5ed8d80004634ffca97bab1c45771265","eea43fbcf67a49b3b04456c49ac8bd2a","3cf8c192151245b8b53db25b6a746996","8dfc7d8ef79d49b2aa3e016ffa444f2d","cbb3f5b8dfe446a5bf8595418ad847e8","f6073a41f0b64a48bc24968f9b33638b","6ad63bc9e0254fa1aae07f55ab05a013","01f311f0f9924eb39febc784322b89e0","2a85bfe7cd214d168eaf8ed5c4e2e805","db5abad73a68491aa4a73b80472d123e","1215fc1fcf1e4364a6e67e36dbcff961","e57eac2e67b94bd78ef35496f6fbeb69","5a9c32b2bf4748b0b87c96ee2fc5b123","d659d9b15ecf448a9fe96f65ddc84547","1dcddfaa954547ec9103bd9f12aa2a57","a43fde84370b4411bf48ce323641a1e5","6b714503207d4da8a8e0af5db6779c0c","d6fa7c26d3f145d6a88f5095bc98b14c","f2e93113b80c446f8a5a7d0cd4981ef0","ebe5e45062af422c90df95f47c6f61c7","6c6c16662cf74a39801ea758ddea77cf","dfaddb4f4f2949fd8da61ea13a529475","a52ac3a8a0bd4dabaea91df0e045bd92","72baf38c211b4961a55ffb0873ca75fc","843c73165c8e439992f0c961ca6cad08","901b8f56ac3e4f7fada11118d92ca91b","1cb412faf9d9433887fc5a61f33b6255","0690e8a03f414983b0d0cca5f8912b1a","612eee67cb3c49d4abe73a52d5d99d28","d1f1d2d295bc4e59965763eed33d4430","3fff025127734d7eaa306abb5efd3a16","fe47e0751ef54b1e811a5a784d2b66af","516c7be67c3848fe990890bfd3338996","9b6d34d725154fb8a8166cc6426a33a3","f2098751c7d54d129c8551b807caaa82","5d713fe402204f48843dfbe8daeed512","5bf9f786d2b84551ba072adde25784b3","6d790f68419b449bbca2697f04a6f182"]},"executionInfo":{"elapsed":11905,"status":"ok","timestamp":1672209037926,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"Ui2HOCflrvgR","outputId":"9f21d723-e2b9-4b1c-92b9-22696064b10c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"641ba41e4d974d2490ec6fc1fbb1a5ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6073a41f0b64a48bc24968f9b33638b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b714503207d4da8a8e0af5db6779c0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0690e8a03f414983b0d0cca5f8912b1a"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4jVuK-V1uq3L","executionInfo":{"status":"ok","timestamp":1672209037927,"user_tz":-540,"elapsed":23,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["#from google.colab import files\n","#uploaded = files.upload()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ttzRlY4Ov0jZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672209037928,"user_tz":-540,"elapsed":20,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"57439116-110d-4304-95da-6ed95eea6999"},"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\t sentiment.dev.1    sentiment.train.1\n","sentiment.dev.0  sentiment.train.0  test_no_label.csv\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BAgztXIBrvgS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672209070189,"user_tz":-540,"elapsed":32272,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"e3e2e102-8582-4bd2-bbd9-83b7a6e8fcd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["it will take some times...\n","make id file finished!\n"]}],"source":["train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"wRh2WjGRrvgS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672209070190,"user_tz":-540,"elapsed":27,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"741f7041-6b1f-47e3-b886-0b09df2b2d6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['101 6581 2833 1012 102',\n"," '101 21688 8013 2326 1012 102',\n"," '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n"," '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n"," '101 1996 3095 2003 5379 1012 102',\n"," '101 2204 3347 2833 1012 102',\n"," '101 2204 2326 1012 102',\n"," '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n"," '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n"," '101 1996 2047 2846 3504 6429 1012 102']"]},"metadata":{},"execution_count":8}],"source":["train_pos[:10]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7koBvfuyNa0E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672209070191,"user_tz":-540,"elapsed":24,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"be393e7d-843a-4b54-ba67-3c3dd483efdc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['101 1045 2001 13718 13534 1012 102',\n"," '101 2061 2006 2000 1996 7570 22974 2229 1010 1996 3059 2003 2236 2448 1997 1996 4971 1012 102',\n"," '101 10124 6240 1998 1037 10228 1997 29022 2292 8525 3401 1012 102',\n"," '101 2498 2428 2569 1004 2025 11007 1997 1996 1002 1035 16371 2213 1035 3976 6415 1012 102',\n"," '101 2117 1010 1996 21475 7570 22974 2063 1010 2009 2003 2012 3217 18436 1012 102',\n"," '101 1045 2018 2000 3477 1002 1035 16371 2213 1035 2000 5587 8808 2000 1996 7570 22974 2063 1012 102',\n"," '101 2016 2409 2033 2045 2001 1037 3715 2005 1996 11225 2006 1996 2217 1012 102',\n"," '101 2024 2017 12489 2033 1029 102',\n"," '101 1045 2001 2025 2183 2000 3477 2005 1996 11225 2006 1996 2217 1012 102',\n"," '101 1045 3641 2009 2302 2292 8525 3401 1010 20856 1010 24444 1010 2030 11225 1012 102']"]},"metadata":{},"execution_count":9}],"source":["train_neg[:10]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JdpQQQMUrvgT","executionInfo":{"status":"ok","timestamp":1672209070191,"user_tz":-540,"elapsed":20,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["class SentimentDataset(object):\n","    def __init__(self, tokenizer, pos, neg):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","        self.label = []\n","\n","        for pos_sent in pos:\n","            self.data += [self._cast_to_int(pos_sent.strip().split())]\n","            self.label += [[1]]\n","        for neg_sent in neg:\n","            self.data += [self._cast_to_int(neg_sent.strip().split())]\n","            self.label += [[0]]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample), np.array(self.label[index])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"wCz5ey8xrvgU","executionInfo":{"status":"ok","timestamp":1672209072599,"user_tz":-540,"elapsed":2427,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n","dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"UuvkMczvrvgU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672209072603,"user_tz":-540,"elapsed":25,"user":{"displayName":"이다원","userId":"11923633709773630529"}},"outputId":"54e6a284-e074-4659-dbb6-187a71648501"},"outputs":[{"output_type":"stream","name":"stdout","text":["(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n","(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n","(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n","        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n","(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n","       22974,  2063,  1012,   102]), array([1]))\n","(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n","(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n","(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n","(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n","       19247,  1012,   102]), array([1]))\n","(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n","        5404,  1012,   102]), array([1]))\n","(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n","(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"]}],"source":["for i, item in enumerate(train_dataset):\n","    print(item)\n","    if i == 10:\n","        break"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"B0wRUBYSrvgU","executionInfo":{"status":"ok","timestamp":1672209072608,"user_tz":-540,"elapsed":25,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["def collate_fn_style(samples):\n","    input_ids, labels = zip(*samples)\n","    max_len = max(len(input_id) for input_id in input_ids)\n","\n","    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n","\n","    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n","                             batch_first=True)\n","\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n","         sorted_indices])\n","    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n","    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n","    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids, labels"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"5saagig0rvgV","executionInfo":{"status":"ok","timestamp":1672209072611,"user_tz":-540,"elapsed":27,"user":{"displayName":"이다원","userId":"11923633709773630529"}}},"outputs":[],"source":["train_batch_size=256 #batch size -> 32 to 128\n","eval_batch_size=128 #batch size -> 64 to 128\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=train_batch_size,\n","                                           shuffle=True, collate_fn=collate_fn_style,\n","                                           pin_memory=True, num_workers=2)\n","dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n","                                         shuffle=True, collate_fn=collate_fn_style, #shuffle false -> true\n","                                         num_workers=2)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":21563,"status":"ok","timestamp":1672209094148,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"zvFqCaCnrvgW","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["192d6eecc7154078bf3c3f1b2c9e6b63","edf80dd9abbd468a811232b2a225bf5c","0edc36754fae49dabde97967d6ace5a9","c7723484cf4a4ce797e68c3172148a43","8921380aa0444784ad06291f3a852da7","457e5333c9544d65b209d5b45ee35eb7","3ad7783a182748d4a6f31fbae0305e82","e7cc1ec7f1b24ea8a8b7c83673f57cc1","003d7d7b31d44deebcad528832d93694","df2328139f824424bd33828ff16d5d63","dd872e664dda434584a041140ed5e5c1"]},"outputId":"65b4241d-c99f-4b9a-9bf8-2bdcfcc17697"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"192d6eecc7154078bf3c3f1b2c9e6b63"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":15}],"source":["# random seed\n","random_seed=42\n","np.random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')\n","model.to(device)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1672209094150,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"dWwhmyMyrvgW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b45d936c-c924-4eb4-a66b-3f97bba08f9c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["model.train()\n","learning_rate = 5e-5\n","optimizer = AdamW(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1672209094151,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"MztU-L83rvgW"},"outputs":[],"source":["def compute_acc(predictions, target_labels):\n","    return (np.array(predictions) == np.array(target_labels)).mean()"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":344058,"status":"error","timestamp":1672209438192,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"DuZfvzpGrvgW","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b68d94a5-9bae-4d6f-d57d-c7e10ad2e84b"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 0:  10%|▉         | 173/1732 [02:47<24:00,  1.08batch/s, loss=0.11]  \n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:08,  3.82it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:06,  4.74it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:05,  5.21it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:05,  5.55it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:04,  5.57it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:01<00:04,  5.55it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:01<00:04,  5.69it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:01<00:03,  6.09it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:03,  5.93it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:03,  6.13it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:03,  6.33it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:02<00:03,  5.87it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:02<00:03,  5.77it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:02<00:03,  5.85it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:02<00:02,  5.93it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:02<00:02,  5.99it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:02<00:02,  6.00it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:03<00:02,  5.96it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:03<00:02,  5.79it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:03<00:02,  5.73it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:03<00:01,  5.84it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:03<00:01,  5.68it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:04<00:01,  5.76it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:04<00:01,  6.08it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:04<00:01,  6.05it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:04<00:00,  6.32it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:04<00:00,  6.26it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:04<00:00,  6.19it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:04<00:00,  6.11it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:05<00:00,  5.84it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:05<00:00,  5.89it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.9705\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 0:  20%|█▉        | 346/1732 [05:37<21:15,  1.09batch/s, loss=0.0545]\n","Eval:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n","Eval:   3%|▎         | 1/32 [00:00<00:07,  3.95it/s]\u001b[A\n","Eval:   6%|▋         | 2/32 [00:00<00:05,  5.02it/s]\u001b[A\n","Eval:   9%|▉         | 3/32 [00:00<00:05,  5.46it/s]\u001b[A\n","Eval:  12%|█▎        | 4/32 [00:00<00:05,  5.51it/s]\u001b[A\n","Eval:  16%|█▌        | 5/32 [00:00<00:04,  5.68it/s]\u001b[A\n","Eval:  19%|█▉        | 6/32 [00:01<00:04,  5.35it/s]\u001b[A\n","Eval:  22%|██▏       | 7/32 [00:01<00:04,  5.48it/s]\u001b[A\n","Eval:  25%|██▌       | 8/32 [00:01<00:04,  5.65it/s]\u001b[A\n","Eval:  28%|██▊       | 9/32 [00:01<00:04,  5.63it/s]\u001b[A\n","Eval:  31%|███▏      | 10/32 [00:01<00:03,  6.00it/s]\u001b[A\n","Eval:  34%|███▍      | 11/32 [00:01<00:03,  5.78it/s]\u001b[A\n","Eval:  38%|███▊      | 12/32 [00:02<00:03,  5.80it/s]\u001b[A\n","Eval:  41%|████      | 13/32 [00:02<00:03,  6.14it/s]\u001b[A\n","Eval:  44%|████▍     | 14/32 [00:02<00:02,  6.01it/s]\u001b[A\n","Eval:  47%|████▋     | 15/32 [00:02<00:02,  6.27it/s]\u001b[A\n","Eval:  50%|█████     | 16/32 [00:02<00:02,  5.98it/s]\u001b[A\n","Eval:  53%|█████▎    | 17/32 [00:02<00:02,  5.92it/s]\u001b[A\n","Eval:  56%|█████▋    | 18/32 [00:03<00:02,  5.90it/s]\u001b[A\n","Eval:  59%|█████▉    | 19/32 [00:03<00:02,  5.91it/s]\u001b[A\n","Eval:  62%|██████▎   | 20/32 [00:03<00:02,  5.95it/s]\u001b[A\n","Eval:  66%|██████▌   | 21/32 [00:03<00:01,  5.79it/s]\u001b[A\n","Eval:  69%|██████▉   | 22/32 [00:03<00:01,  5.73it/s]\u001b[A\n","Eval:  72%|███████▏  | 23/32 [00:04<00:01,  5.79it/s]\u001b[A\n","Eval:  75%|███████▌  | 24/32 [00:04<00:01,  5.57it/s]\u001b[A\n","Eval:  78%|███████▊  | 25/32 [00:04<00:01,  5.45it/s]\u001b[A\n","Eval:  81%|████████▏ | 26/32 [00:04<00:01,  5.60it/s]\u001b[A\n","Eval:  84%|████████▍ | 27/32 [00:04<00:00,  5.77it/s]\u001b[A\n","Eval:  88%|████████▊ | 28/32 [00:04<00:00,  6.08it/s]\u001b[A\n","Eval:  91%|█████████ | 29/32 [00:05<00:00,  6.06it/s]\u001b[A\n","Eval:  94%|█████████▍| 30/32 [00:05<00:00,  6.00it/s]\u001b[A\n","Eval:  97%|█████████▋| 31/32 [00:05<00:00,  5.83it/s]\u001b[A\n","                                                     \u001b[A"]},{"output_type":"stream","name":"stdout","text":["Acc for model which have lower valid loss:  0.973\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch 0:  20%|█▉        | 346/1732 [05:43<22:56,  1.01batch/s, loss=0.0545]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e7ca8eb04b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlowest_valid_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Acc for model which have lower valid loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0mlowest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train_epoch = 3\n","lowest_valid_loss = 9999.\n","for epoch in range(train_epoch):\n","    with tqdm(train_loader, unit=\"batch\") as tepoch:\n","        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n","            tepoch.set_description(f\"Epoch {epoch}\")\n","            input_ids = input_ids.to(device)\n","            attention_mask = attention_mask.to(device)\n","            token_type_ids = token_type_ids.to(device)\n","            position_ids = position_ids.to(device)\n","            labels = labels.to(device, dtype=torch.long)\n","\n","            optimizer.zero_grad()\n","\n","            # output = model(input_ids=input_ids,\n","            #                attention_mask=attention_mask,\n","            #                token_type_ids=token_type_ids,\n","            #                position_ids=position_ids,\n","            #                labels=labels)\n","            output = model(input_ids=input_ids,\n","                        attention_mask=attention_mask,\n","                        token_type_ids=token_type_ids,\n","                        position_ids=position_ids,\n","                        labels=labels)\n","\n","            loss = output.loss\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            tepoch.set_postfix(loss=loss.item())\n","            if iteration != 0 and iteration % int(len(train_loader) / 10) == 0:\n","                # Evaluate the model five times per epoch\n","                with torch.no_grad():\n","                    model.eval()\n","                    valid_losses = []\n","                    predictions = []\n","                    target_labels = []\n","                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n","                                                                                                desc='Eval',\n","                                                                                                position=1,\n","                                                                                                leave=None):\n","                        input_ids = input_ids.to(device)\n","                        attention_mask = attention_mask.to(device)\n","                        token_type_ids = token_type_ids.to(device)\n","                        position_ids = position_ids.to(device)\n","                        labels = labels.to(device, dtype=torch.long)\n","\n","                        # output = model(input_ids=input_ids,\n","                        #                attention_mask=attention_mask,\n","                        #                token_type_ids=token_type_ids,\n","                        #                position_ids=position_ids,\n","                        #                labels=labels)\n","                        output = model(input_ids=input_ids,\n","                                        attention_mask=attention_mask,\n","                                       token_type_ids=token_type_ids,\n","                                      position_ids=position_ids,     \n","                                        labels=labels)\n","\n","                        logits = output.logits\n","                        loss = output.loss\n","                        valid_losses.append(loss.item())\n","\n","                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","                        batch_labels = [int(example) for example in labels]\n","\n","                        predictions += batch_predictions\n","                        target_labels += batch_labels\n","\n","                acc = compute_acc(predictions, target_labels)\n","                valid_loss = sum(valid_losses) / len(valid_losses)\n","                if lowest_valid_loss > valid_loss:\n","                    print('Acc for model which have lower valid loss: ', acc)\n","                    torch.save(model.state_dict(), \"./pytorch_model.bin\")\n","                    lowest_valid_loss = valid_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"aborted","timestamp":1672209438194,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"P95gtlnurvgX"},"outputs":[],"source":["import pandas as pd\n","test_df = pd.read_csv('test_no_label.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1672209438195,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"cLDzC10ErvgX"},"outputs":[],"source":["test_dataset = test_df['Id']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"aborted","timestamp":1672209438195,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"jnt693N0rvgX"},"outputs":[],"source":["def make_id_file_test(tokenizer, test_dataset):\n","    data_strings = []\n","    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n","    for item in id_file_data:\n","        data_strings.append(' '.join([str(k) for k in item]))\n","    return data_strings"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1672209438196,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"7C5PpXtlrvgY"},"outputs":[],"source":["test = make_id_file_test(tokenizer, test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1672209438196,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"1aqse7SHrvgY"},"outputs":[],"source":["test[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"aborted","timestamp":1672209438197,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"cZi14gnnrvgY"},"outputs":[],"source":["class SentimentTestDataset(object):\n","    def __init__(self, tokenizer, test):\n","        self.tokenizer = tokenizer\n","        self.data = []\n","\n","        for sent in test:\n","            self.data += [self._cast_to_int(sent.strip().split())]\n","\n","    def _cast_to_int(self, sample):\n","        return [int(word_id) for word_id in sample]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        sample = self.data[index]\n","        return np.array(sample)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"aborted","timestamp":1672209438197,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"erHjGE9rrvgY"},"outputs":[],"source":["test_dataset = SentimentTestDataset(tokenizer, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":29,"status":"aborted","timestamp":1672209438197,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"y03-nDX9rvgZ"},"outputs":[],"source":["def collate_fn_style_test(samples):\n","    input_ids = samples\n","    max_len = max(len(input_id) for input_id in input_ids)\n","\n","    #sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1] #bug\n","    sorted_indices = [i for i in range(len(input_ids))]\n","    \n","    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],batch_first=True)\n","    attention_mask = torch.tensor(\n","        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n","         sorted_indices])\n","    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n","    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n","\n","    return input_ids, attention_mask, token_type_ids, position_ids"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"aborted","timestamp":1672209438198,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"gZ0l1HparvgZ"},"outputs":[],"source":["test_batch_size = 32\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n","                                          shuffle=False, collate_fn=collate_fn_style_test,\n","                                          num_workers=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"aborted","timestamp":1672209438198,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"XoSHTbJUrvgZ"},"outputs":[],"source":["with torch.no_grad():\n","    model.eval()\n","    predictions = []\n","    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n","                                                                        desc='Test',\n","                                                                        position=1,\n","                                                                        leave=None):\n","\n","        input_ids = input_ids.to(device)\n","        attention_mask = attention_mask.to(device)\n","        token_type_ids = token_type_ids.to(device)\n","        position_ids = position_ids.to(device)\n","\n","        # output = model(input_ids=input_ids,\n","        #                attention_mask=attention_mask,\n","        #                token_type_ids=token_type_ids,\n","        #                position_ids=position_ids)\n","        output = model(input_ids=input_ids,\n","                      attention_mask=attention_mask,\n","                      token_type_ids=token_type_ids,\n","                      position_ids=position_ids)\n","\n","        logits = output.logits\n","        print(logits)\n","        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n","        predictions += batch_predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31,"status":"aborted","timestamp":1672209438199,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"tGO3aS-VrvgZ"},"outputs":[],"source":["test_df['Category'] = predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":31,"status":"aborted","timestamp":1672209438199,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"VndXxal3rvgZ"},"outputs":[],"source":["test_df.to_csv('submission_t5.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"aborted","timestamp":1672209438200,"user":{"displayName":"이다원","userId":"11923633709773630529"},"user_tz":-540},"id":"V43-rLcOm364"},"outputs":[],"source":["print(lowest_valid_loss)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"641ba41e4d974d2490ec6fc1fbb1a5ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b58f32031b04fd295eb84bbd0de7873","IPY_MODEL_73e05f6faeae45ce9f03d96d98a078e7","IPY_MODEL_0275038dfbcf4451a07d0198de02eef3"],"layout":"IPY_MODEL_3a7acf84b3cc4932bba93044ee4dc5f3"}},"7b58f32031b04fd295eb84bbd0de7873":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_080cde53beb3423d8e600dc30226ef9d","placeholder":"​","style":"IPY_MODEL_5ed8d80004634ffca97bab1c45771265","value":"Downloading: 100%"}},"73e05f6faeae45ce9f03d96d98a078e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eea43fbcf67a49b3b04456c49ac8bd2a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cf8c192151245b8b53db25b6a746996","value":28}},"0275038dfbcf4451a07d0198de02eef3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8dfc7d8ef79d49b2aa3e016ffa444f2d","placeholder":"​","style":"IPY_MODEL_cbb3f5b8dfe446a5bf8595418ad847e8","value":" 28.0/28.0 [00:00&lt;00:00, 2.04kB/s]"}},"3a7acf84b3cc4932bba93044ee4dc5f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"080cde53beb3423d8e600dc30226ef9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ed8d80004634ffca97bab1c45771265":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eea43fbcf67a49b3b04456c49ac8bd2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cf8c192151245b8b53db25b6a746996":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8dfc7d8ef79d49b2aa3e016ffa444f2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbb3f5b8dfe446a5bf8595418ad847e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6073a41f0b64a48bc24968f9b33638b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ad63bc9e0254fa1aae07f55ab05a013","IPY_MODEL_01f311f0f9924eb39febc784322b89e0","IPY_MODEL_2a85bfe7cd214d168eaf8ed5c4e2e805"],"layout":"IPY_MODEL_db5abad73a68491aa4a73b80472d123e"}},"6ad63bc9e0254fa1aae07f55ab05a013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1215fc1fcf1e4364a6e67e36dbcff961","placeholder":"​","style":"IPY_MODEL_e57eac2e67b94bd78ef35496f6fbeb69","value":"Downloading: 100%"}},"01f311f0f9924eb39febc784322b89e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a9c32b2bf4748b0b87c96ee2fc5b123","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d659d9b15ecf448a9fe96f65ddc84547","value":570}},"2a85bfe7cd214d168eaf8ed5c4e2e805":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dcddfaa954547ec9103bd9f12aa2a57","placeholder":"​","style":"IPY_MODEL_a43fde84370b4411bf48ce323641a1e5","value":" 570/570 [00:00&lt;00:00, 43.3kB/s]"}},"db5abad73a68491aa4a73b80472d123e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1215fc1fcf1e4364a6e67e36dbcff961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e57eac2e67b94bd78ef35496f6fbeb69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a9c32b2bf4748b0b87c96ee2fc5b123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d659d9b15ecf448a9fe96f65ddc84547":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dcddfaa954547ec9103bd9f12aa2a57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a43fde84370b4411bf48ce323641a1e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b714503207d4da8a8e0af5db6779c0c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6fa7c26d3f145d6a88f5095bc98b14c","IPY_MODEL_f2e93113b80c446f8a5a7d0cd4981ef0","IPY_MODEL_ebe5e45062af422c90df95f47c6f61c7"],"layout":"IPY_MODEL_6c6c16662cf74a39801ea758ddea77cf"}},"d6fa7c26d3f145d6a88f5095bc98b14c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfaddb4f4f2949fd8da61ea13a529475","placeholder":"​","style":"IPY_MODEL_a52ac3a8a0bd4dabaea91df0e045bd92","value":"Downloading: 100%"}},"f2e93113b80c446f8a5a7d0cd4981ef0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72baf38c211b4961a55ffb0873ca75fc","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_843c73165c8e439992f0c961ca6cad08","value":231508}},"ebe5e45062af422c90df95f47c6f61c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_901b8f56ac3e4f7fada11118d92ca91b","placeholder":"​","style":"IPY_MODEL_1cb412faf9d9433887fc5a61f33b6255","value":" 232k/232k [00:00&lt;00:00, 256kB/s]"}},"6c6c16662cf74a39801ea758ddea77cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfaddb4f4f2949fd8da61ea13a529475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a52ac3a8a0bd4dabaea91df0e045bd92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72baf38c211b4961a55ffb0873ca75fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"843c73165c8e439992f0c961ca6cad08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"901b8f56ac3e4f7fada11118d92ca91b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cb412faf9d9433887fc5a61f33b6255":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0690e8a03f414983b0d0cca5f8912b1a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_612eee67cb3c49d4abe73a52d5d99d28","IPY_MODEL_d1f1d2d295bc4e59965763eed33d4430","IPY_MODEL_3fff025127734d7eaa306abb5efd3a16"],"layout":"IPY_MODEL_fe47e0751ef54b1e811a5a784d2b66af"}},"612eee67cb3c49d4abe73a52d5d99d28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_516c7be67c3848fe990890bfd3338996","placeholder":"​","style":"IPY_MODEL_9b6d34d725154fb8a8166cc6426a33a3","value":"Downloading: 100%"}},"d1f1d2d295bc4e59965763eed33d4430":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2098751c7d54d129c8551b807caaa82","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d713fe402204f48843dfbe8daeed512","value":466062}},"3fff025127734d7eaa306abb5efd3a16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bf9f786d2b84551ba072adde25784b3","placeholder":"​","style":"IPY_MODEL_6d790f68419b449bbca2697f04a6f182","value":" 466k/466k [00:01&lt;00:00, 437kB/s]"}},"fe47e0751ef54b1e811a5a784d2b66af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"516c7be67c3848fe990890bfd3338996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b6d34d725154fb8a8166cc6426a33a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2098751c7d54d129c8551b807caaa82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d713fe402204f48843dfbe8daeed512":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bf9f786d2b84551ba072adde25784b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d790f68419b449bbca2697f04a6f182":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"192d6eecc7154078bf3c3f1b2c9e6b63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edf80dd9abbd468a811232b2a225bf5c","IPY_MODEL_0edc36754fae49dabde97967d6ace5a9","IPY_MODEL_c7723484cf4a4ce797e68c3172148a43"],"layout":"IPY_MODEL_8921380aa0444784ad06291f3a852da7"}},"edf80dd9abbd468a811232b2a225bf5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_457e5333c9544d65b209d5b45ee35eb7","placeholder":"​","style":"IPY_MODEL_3ad7783a182748d4a6f31fbae0305e82","value":"Downloading: 100%"}},"0edc36754fae49dabde97967d6ace5a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7cc1ec7f1b24ea8a8b7c83673f57cc1","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_003d7d7b31d44deebcad528832d93694","value":440473133}},"c7723484cf4a4ce797e68c3172148a43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df2328139f824424bd33828ff16d5d63","placeholder":"​","style":"IPY_MODEL_dd872e664dda434584a041140ed5e5c1","value":" 440M/440M [00:15&lt;00:00, 34.0MB/s]"}},"8921380aa0444784ad06291f3a852da7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"457e5333c9544d65b209d5b45ee35eb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ad7783a182748d4a6f31fbae0305e82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7cc1ec7f1b24ea8a8b7c83673f57cc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"003d7d7b31d44deebcad528832d93694":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df2328139f824424bd33828ff16d5d63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd872e664dda434584a041140ed5e5c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}