{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjsOpcpEDqhs",
        "outputId": "47b8f973-06d5-49ea-bbe6-be5c86df5249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SCUvkZSDsrU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pdb\n",
        "import argparse\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertTokenizer,\n",
        "    AutoConfig,\n",
        "    AdamW\n",
        ")\n",
        "\n",
        "#new model\n",
        "from transformers import (\n",
        "\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn5IeERXDstp"
      },
      "outputs": [],
      "source": [
        "def make_id_file(task, tokenizer):\n",
        "    def make_data_strings(file_name):\n",
        "        data_strings = []\n",
        "        with open(os.path.join(file_name), 'r', encoding='utf-8') as f:\n",
        "            id_file_data = [tokenizer.encode(line.lower()) for line in f.readlines()]\n",
        "        for item in id_file_data:\n",
        "            data_strings.append(' '.join([str(k) for k in item]))\n",
        "        return data_strings\n",
        "    \n",
        "    print('it will take some times...')\n",
        "    train_pos = make_data_strings('sentiment.train.1')\n",
        "    train_neg = make_data_strings('sentiment.train.0')\n",
        "    dev_pos = make_data_strings('sentiment.dev.1')\n",
        "    dev_neg = make_data_strings('sentiment.dev.0')\n",
        "\n",
        "    print('make id file finished!')\n",
        "    return train_pos, train_neg, dev_pos, dev_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiBIJD8lDswH"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "M4rE68Y0DsyZ",
        "outputId": "077a122e-ac1a-40f4-d876-8a5fc8e96c90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c14c6bf-537d-48b6-a785-826c3d7b4707\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2c14c6bf-537d-48b6-a785-826c3d7b4707\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_no_label.csv to test_no_label (1).csv\n",
            "Saving sentiment.dev.1 to sentiment.dev (1).1\n",
            "Saving sentiment.dev.0 to sentiment.dev (1).0\n",
            "Saving sentiment.train.0 to sentiment.train (1).0\n",
            "Saving sentiment.train.1 to sentiment.train (1).1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757pnhOQDs0m",
        "outputId": "843dbb71-a805-44db-937a-e95e8c278eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " pytorch_model.bin     'sentiment.dev (1).1'\t submission.csv\n",
            " sample_data\t        sentiment.train.0\t'test_no_label (1).csv'\n",
            " sentiment.dev.0        sentiment.train.1\t test_no_label.csv\n",
            " sentiment.dev.1       'sentiment.train (1).0'\n",
            "'sentiment.dev (1).0'  'sentiment.train (1).1'\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4XnjVugDs3V",
        "outputId": "73762017-72d6-4597-e622-5f722b464e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it will take some times...\n",
            "make id file finished!\n"
          ]
        }
      ],
      "source": [
        "train_pos, train_neg, dev_pos, dev_neg = make_id_file('yelp', tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQwFRHOrD1gc",
        "outputId": "2df57c68-bc68-4ecc-892a-676a79299f92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 6581 2833 1012 102',\n",
              " '101 21688 8013 2326 1012 102',\n",
              " '101 2027 2036 2031 3679 19247 1998 3256 6949 2029 2003 2428 2204 1012 102',\n",
              " '101 2009 1005 1055 1037 2204 15174 2098 7570 22974 2063 1012 102',\n",
              " '101 1996 3095 2003 5379 1012 102',\n",
              " '101 2204 3347 2833 1012 102',\n",
              " '101 2204 2326 1012 102',\n",
              " '101 11350 1997 2154 2003 25628 1998 7167 1997 19247 1012 102',\n",
              " '101 2307 2173 2005 6265 2030 3347 27962 1998 5404 1012 102',\n",
              " '101 1996 2047 2846 3504 6429 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "train_pos[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F10jo_yqD1im"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(object):\n",
        "    def __init__(self, tokenizer, pos, neg):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for pos_sent in pos:\n",
        "            self.data += [self._cast_to_int(pos_sent.strip().split())]\n",
        "            self.label += [[1]]\n",
        "        for neg_sent in neg:\n",
        "            self.data += [self._cast_to_int(neg_sent.strip().split())]\n",
        "            self.label += [[0]]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample), np.array(self.label[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQYJWzlgD1ku"
      },
      "outputs": [],
      "source": [
        "train_dataset = SentimentDataset(tokenizer, train_pos, train_neg)\n",
        "dev_dataset = SentimentDataset(tokenizer, dev_pos, dev_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_EZGiBBD1nB",
        "outputId": "70cf953c-000f-4546-b5d0-c6ef0cbf24b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([ 101, 6581, 2833, 1012,  102]), array([1]))\n",
            "(array([  101, 21688,  8013,  2326,  1012,   102]), array([1]))\n",
            "(array([  101,  2027,  2036,  2031,  3679, 19247,  1998,  3256,  6949,\n",
            "        2029,  2003,  2428,  2204,  1012,   102]), array([1]))\n",
            "(array([  101,  2009,  1005,  1055,  1037,  2204, 15174,  2098,  7570,\n",
            "       22974,  2063,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 3095, 2003, 5379, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 3347, 2833, 1012,  102]), array([1]))\n",
            "(array([ 101, 2204, 2326, 1012,  102]), array([1]))\n",
            "(array([  101, 11350,  1997,  2154,  2003, 25628,  1998,  7167,  1997,\n",
            "       19247,  1012,   102]), array([1]))\n",
            "(array([  101,  2307,  2173,  2005,  6265,  2030,  3347, 27962,  1998,\n",
            "        5404,  1012,   102]), array([1]))\n",
            "(array([ 101, 1996, 2047, 2846, 3504, 6429, 1012,  102]), array([1]))\n",
            "(array([ 101, 2023, 2173, 2001, 2200, 2204, 1012,  102]), array([1]))\n"
          ]
        }
      ],
      "source": [
        "for i, item in enumerate(train_dataset):\n",
        "    print(item)\n",
        "    if i == 10:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRsMReriD1pP"
      },
      "outputs": [],
      "source": [
        "def collate_fn_style(samples):\n",
        "    input_ids, labels = zip(*samples)\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "    sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1]\n",
        "\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],\n",
        "                             batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "    labels = torch.tensor(np.stack(labels, axis=0)[sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY4KaQcZRg48"
      },
      "outputs": [],
      "source": [
        "train_batch_size=256\n",
        "eval_batch_size=512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=train_batch_size,\n",
        "                                           shuffle=True, collate_fn=collate_fn_style,\n",
        "                                           pin_memory=True, num_workers=2)\n",
        "dev_loader = torch.utils.data.DataLoader(dev_dataset, batch_size=eval_batch_size,\n",
        "                                         shuffle=False, collate_fn=collate_fn_style,\n",
        "                                         num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce4ihxEPRg7V",
        "outputId": "11209bf4-6a0d-4857-be8c-e8127a1491f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# random seed\n",
        "random_seed=42\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2K24bHjRg9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "015ef819-de1b-4da2-bffc-bd5326fdb9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "learning_rate = 5e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer = optimizer, lr_lambda = lambda epoch : 0.9** epoch, last_epoch=-1,verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9MYmh9Rg_z"
      },
      "outputs": [],
      "source": [
        "def compute_acc(predictions, target_labels):\n",
        "    return (np.array(predictions) == np.array(target_labels)).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "iter_x = []\n",
        "max_iteration = 0\n",
        "acc_y = []\n",
        "loss_y = []\n",
        "\n",
        "starttime = time.time()"
      ],
      "metadata": {
        "id": "ATlAf_o7lBBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwzlciAiRhCQ",
        "outputId": "192d6abd-9f1b-4b8a-f763-01f0f09b993e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  10%|▉         | 173/1732 [00:39<06:01,  4.31batch/s, loss=0.00247]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.97it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "                                                   \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  20%|█▉        | 346/1732 [01:21<05:27,  4.24batch/s, loss=0.00958]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.05it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.56it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.05it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.92it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "                                                   \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  30%|██▉       | 519/1732 [02:03<04:31,  4.46batch/s, loss=0.00557]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.84it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "                                                   \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  40%|███▉      | 692/1732 [02:45<04:06,  4.23batch/s, loss=0.0153]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.68it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.89it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.45it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.96it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 0:  50%|████▉     | 865/1732 [03:26<03:25,  4.23batch/s, loss=0.00815]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.89it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.06it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.59it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.04it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "Epoch 0:  60%|█████▉    | 1038/1732 [04:07<02:39,  4.35batch/s, loss=0.0318]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.78it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.96it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.50it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.90it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 0:  70%|██████▉   | 1211/1732 [04:48<01:56,  4.47batch/s, loss=0.00885]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.04it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "Epoch 0:  80%|███████▉  | 1384/1732 [05:29<01:18,  4.41batch/s, loss=0.000526]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.89it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.06it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.56it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.05it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.83it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "Epoch 0:  90%|████████▉ | 1557/1732 [06:10<00:39,  4.46batch/s, loss=0.0125]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.03it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.47it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "                                                   \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acc for model which have lower valid loss:  0.98125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|█████████▉| 1730/1732 [06:52<00:00,  4.15batch/s, loss=0.0137] \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.72it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.93it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.47it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.80it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 0: 100%|██████████| 1732/1732 [06:54<00:00,  4.18batch/s, loss=0.00146]\n",
            "Epoch 1:  10%|▉         | 173/1732 [00:40<05:49,  4.47batch/s, loss=0.00544]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.57it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.82it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.40it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.78it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.78it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.20it/s]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 346/1732 [01:20<05:14,  4.41batch/s, loss=0.00272]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.73it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.94it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.48it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.99it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 519/1732 [02:01<04:32,  4.45batch/s, loss=0.00842]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.05it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.55it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.92it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.83it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 692/1732 [02:42<03:58,  4.36batch/s, loss=0.00475]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.86it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.04it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.55it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.04it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.92it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.83it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 865/1732 [03:23<03:08,  4.59batch/s, loss=0.0118] \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.83it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.01it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.83it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 1038/1732 [04:04<02:34,  4.50batch/s, loss=0.0269]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.83it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 1211/1732 [04:45<02:03,  4.22batch/s, loss=0.0138] \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.05it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.55it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.03it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 1384/1732 [05:26<01:20,  4.34batch/s, loss=0.0133] \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.64it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.89it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.45it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.97it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.80it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.20it/s]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 1557/1732 [06:07<00:39,  4.40batch/s, loss=0.0103]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.80it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.80it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 1730/1732 [06:48<00:00,  4.44batch/s, loss=0.00253]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.82it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 1: 100%|██████████| 1732/1732 [06:49<00:00,  4.23batch/s, loss=0.00288]\n",
            "Epoch 2:  10%|▉         | 173/1732 [00:39<06:07,  4.24batch/s, loss=0.00142]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.67it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.87it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.42it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.92it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.79it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.85it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.79it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\u001b[A\n",
            "Epoch 2:  20%|█▉        | 346/1732 [01:20<05:06,  4.53batch/s, loss=0.0164]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.81it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.01it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.99it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.80it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\u001b[A\n",
            "Epoch 2:  30%|██▉       | 519/1732 [02:01<04:39,  4.34batch/s, loss=0.00896]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.81it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.54it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.03it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.89it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 2:  40%|███▉      | 692/1732 [02:42<03:58,  4.36batch/s, loss=0.00932]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.72it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.92it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.47it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.98it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.87it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.79it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.20it/s]\u001b[A\n",
            "Epoch 2:  50%|████▉     | 865/1732 [03:23<03:16,  4.41batch/s, loss=0.00527]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.79it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.97it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.85it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.90it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "Epoch 2:  60%|█████▉    | 1038/1732 [04:04<02:40,  4.33batch/s, loss=0.0113] \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.78it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.97it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.50it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.85it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.90it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.22it/s]\u001b[A\n",
            "Epoch 2:  70%|██████▉   | 1211/1732 [04:45<02:01,  4.30batch/s, loss=0.00319]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.81it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.00it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.53it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.02it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.91it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.82it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.24it/s]\u001b[A\n",
            "Epoch 2:  80%|███████▉  | 1384/1732 [05:26<01:20,  4.34batch/s, loss=0.0149]  \n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.80it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.97it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.99it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.83it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.23it/s]\u001b[A\n",
            "Epoch 2:  90%|████████▉ | 1557/1732 [06:07<00:39,  4.38batch/s, loss=0.00512]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.57it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  4.86it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.43it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  5.95it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.81it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.20it/s]\u001b[A\n",
            "Epoch 2: 100%|█████████▉| 1730/1732 [06:48<00:00,  4.22batch/s, loss=0.00107]\n",
            "Eval:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            "Eval:  12%|█▎        | 1/8 [00:00<00:01,  3.86it/s]\u001b[A\n",
            "Eval:  25%|██▌       | 2/8 [00:00<00:01,  5.02it/s]\u001b[A\n",
            "Eval:  38%|███▊      | 3/8 [00:00<00:00,  5.52it/s]\u001b[A\n",
            "Eval:  50%|█████     | 4/8 [00:00<00:00,  6.00it/s]\u001b[A\n",
            "Eval:  62%|██████▎   | 5/8 [00:00<00:00,  5.86it/s]\u001b[A\n",
            "Eval:  75%|███████▌  | 6/8 [00:01<00:00,  5.88it/s]\u001b[A\n",
            "Eval:  88%|████████▊ | 7/8 [00:01<00:00,  5.81it/s]\u001b[A\n",
            "Eval: 100%|██████████| 8/8 [00:01<00:00,  6.21it/s]\u001b[A\n",
            "Epoch 2: 100%|██████████| 1732/1732 [06:50<00:00,  4.22batch/s, loss=0.0066]\n"
          ]
        }
      ],
      "source": [
        "train_epoch = 3\n",
        "lowest_valid_loss = 9999.\n",
        "for epoch in range(train_epoch):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        for iteration, (input_ids, attention_mask, token_type_ids, position_ids, labels) in enumerate(tepoch):\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            position_ids = position_ids.to(device)\n",
        "            labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # output = model(input_ids=input_ids,\n",
        "            #                attention_mask=attention_mask,\n",
        "            #                token_type_ids=token_type_ids,\n",
        "            #                position_ids=position_ids,\n",
        "            #                labels=labels)\n",
        "            output = model(input_ids=input_ids,\n",
        "                        attention_mask=attention_mask,\n",
        "                        token_type_ids=token_type_ids,\n",
        "                        position_ids=position_ids,\n",
        "                        labels=labels)\n",
        "\n",
        "            loss = output.loss\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "            #### matplotlib ###\n",
        "            if max_iteration < iteration:\n",
        "                max_iteration = iteration\n",
        "                if epoch>0:\n",
        "                    assert False\n",
        "            ### matplotlib ###\n",
        "\n",
        "            if iteration != 0 and iteration % int(len(train_loader) / 10) == 0:\n",
        "                # Evaluate the model five times per epoch\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    valid_losses = []\n",
        "                    predictions = []\n",
        "                    target_labels = []\n",
        "                    for input_ids, attention_mask, token_type_ids, position_ids, labels in tqdm(dev_loader,\n",
        "                                                                                                desc='Eval',\n",
        "                                                                                                position=1,\n",
        "                                                                                                leave=None):\n",
        "                        input_ids = input_ids.to(device)\n",
        "                        attention_mask = attention_mask.to(device)\n",
        "                        token_type_ids = token_type_ids.to(device)\n",
        "                        position_ids = position_ids.to(device)\n",
        "                        labels = labels.to(device, dtype=torch.long)\n",
        "\n",
        "                        # output = model(input_ids=input_ids,\n",
        "                        #                attention_mask=attention_mask,\n",
        "                        #                token_type_ids=token_type_ids,\n",
        "                        #                position_ids=position_ids,\n",
        "                        #                labels=labels)\n",
        "                        output = model(input_ids=input_ids,\n",
        "                                        attention_mask=attention_mask,\n",
        "                                        token_type_ids=token_type_ids,\n",
        "                                        position_ids=position_ids,\n",
        "                                        labels=labels)\n",
        "\n",
        "                        logits = output.logits\n",
        "                        loss = output.loss\n",
        "                        valid_losses.append(loss.item())\n",
        "\n",
        "                        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "                        batch_labels = [int(example) for example in labels]\n",
        "\n",
        "                        predictions += batch_predictions\n",
        "                        target_labels += batch_labels\n",
        "\n",
        "                acc = compute_acc(predictions, target_labels)\n",
        "                valid_loss = sum(valid_losses) / len(valid_losses)\n",
        "\n",
        "                ### matplotlib start ###\n",
        "                \n",
        "                iter_x.append(iteration)\n",
        "                acc_y.append(acc)\n",
        "                loss_y.append(valid_loss)\n",
        "                \n",
        "                ### matplotlib end ###\n",
        "    \n",
        "                if lowest_valid_loss > valid_loss:\n",
        "                    print('Acc for model which have lower valid loss: ', acc)\n",
        "                    torch.save(model.state_dict(), \"./pytorch_model.bin\")\n",
        "                    lowest_valid_loss = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "endtime = time.time()"
      ],
      "metadata": {
        "id": "piUVQX-drNY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXrqBOzwRhEi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test_df = pd.read_csv('test_no_label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys4nWR27D1rZ"
      },
      "outputs": [],
      "source": [
        "test_dataset = test_df['Id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZaefFdVD1to"
      },
      "outputs": [],
      "source": [
        "def make_id_file_test(tokenizer, test_dataset):\n",
        "    data_strings = []\n",
        "    id_file_data = [tokenizer.encode(sent.lower()) for sent in test_dataset]\n",
        "    for item in id_file_data:\n",
        "        data_strings.append(' '.join([str(k) for k in item]))\n",
        "    return data_strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATWrOSqtRyat"
      },
      "outputs": [],
      "source": [
        "test = make_id_file_test(tokenizer, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BZMej7nRydD",
        "outputId": "b9b920df-1a57-4844-d2f5-e5d17eba0195"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['101 2009 1005 1055 1037 2878 2047 3325 1998 2047 26389 2169 2051 2017 2175 1012 102',\n",
              " '101 2061 15640 2013 2019 2214 5440 1012 102',\n",
              " '101 2009 2003 1996 2087 14469 7273 1999 1996 3028 1012 102',\n",
              " '101 2079 2025 3696 1037 10084 2007 2122 2111 1012 102',\n",
              " '101 1045 2001 6091 1998 2016 2081 2033 2514 2061 6625 1998 6160 1012 102',\n",
              " '101 1996 2069 2518 2057 2363 2008 2001 2980 2001 1996 4157 1012 102',\n",
              " '101 2053 1010 2025 1996 3924 2012 2004 2226 1010 1996 3924 1999 3502 2152 1012 102',\n",
              " '101 2027 3288 2009 2041 2392 2005 2017 1998 2024 2200 14044 1012 102',\n",
              " '101 4606 1996 12043 2106 1050 1005 1056 2130 2113 2129 2000 2147 1996 3274 1012 102',\n",
              " '101 2027 2031 2019 6581 4989 1997 25025 2015 2000 5454 2013 1012 102']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "farEBxKeRyfJ"
      },
      "outputs": [],
      "source": [
        "class SentimentTestDataset(object):\n",
        "    def __init__(self, tokenizer, test):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = []\n",
        "\n",
        "        for sent in test:\n",
        "            self.data += [self._cast_to_int(sent.strip().split())]\n",
        "\n",
        "    def _cast_to_int(self, sample):\n",
        "        return [int(word_id) for word_id in sample]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        return np.array(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTBmgYaPR2gv"
      },
      "outputs": [],
      "source": [
        "test_dataset = SentimentTestDataset(tokenizer, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex4Thvg5R2jO"
      },
      "outputs": [],
      "source": [
        "def collate_fn_style_test(samples):\n",
        "    input_ids = samples\n",
        "    max_len = max(len(input_id) for input_id in input_ids)\n",
        "\n",
        "    #sorted_indices = np.argsort([len(input_id) for input_id in input_ids])[::-1] #bug\n",
        "    sorted_indices = [i for i in range(len(input_ids))]\n",
        "    input_ids = pad_sequence([torch.tensor(input_ids[index]) for index in sorted_indices],batch_first=True)\n",
        "    attention_mask = torch.tensor(\n",
        "        [[1] * len(input_ids[index]) + [0] * (max_len - len(input_ids[index])) for index in\n",
        "         sorted_indices])\n",
        "    token_type_ids = torch.tensor([[0] * len(input_ids[index]) for index in sorted_indices])\n",
        "    position_ids = torch.tensor([list(range(len(input_ids[index]))) for index in sorted_indices])\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, position_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL74F2p6R2lW"
      },
      "outputs": [],
      "source": [
        "test_batch_size = 32\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size,\n",
        "                                          shuffle=False, collate_fn=collate_fn_style_test,\n",
        "                                          num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9NYflbMR64t",
        "outputId": "efc56a5b-c896-4892-e14d-116277843c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:   0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            "Test:   3%|▎         | 1/32 [00:00<00:04,  7.71it/s]\u001b[A\n",
            "Test:  19%|█▉        | 6/32 [00:00<00:00, 29.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.0411,  4.8313],\n",
            "        [ 3.2995, -4.6589],\n",
            "        [-4.1118,  4.8655],\n",
            "        [ 4.7272, -5.6903],\n",
            "        [-4.0732,  4.8711],\n",
            "        [ 4.5798, -5.2983],\n",
            "        [ 4.4110, -5.3995],\n",
            "        [-4.0496,  4.7968],\n",
            "        [ 4.6401, -5.5892],\n",
            "        [-4.0488,  4.7941],\n",
            "        [-4.1775,  4.9843],\n",
            "        [ 4.9724, -5.6570],\n",
            "        [ 4.0067, -4.6350],\n",
            "        [-3.9325,  4.5799],\n",
            "        [-4.1800,  4.9865],\n",
            "        [ 4.0908, -4.9165],\n",
            "        [-0.8814,  0.2969],\n",
            "        [-4.1002,  4.8246],\n",
            "        [ 4.2302, -5.0265],\n",
            "        [ 4.3738, -5.4949],\n",
            "        [ 3.8402, -3.5794],\n",
            "        [-3.9564,  4.6886],\n",
            "        [ 4.3235, -5.2375],\n",
            "        [-4.2091,  4.9517],\n",
            "        [ 4.1696, -4.7717],\n",
            "        [ 3.9158, -4.5786],\n",
            "        [-4.1568,  4.9686],\n",
            "        [-4.1478,  4.9287],\n",
            "        [ 0.9503, -1.7326],\n",
            "        [ 4.8920, -5.6767],\n",
            "        [ 4.9894, -5.5608],\n",
            "        [ 3.5766, -3.2342]], device='cuda:0')\n",
            "tensor([[ 4.6141, -5.2124],\n",
            "        [ 4.5910, -5.4764],\n",
            "        [ 4.8474, -5.5606],\n",
            "        [ 3.2374, -4.6437],\n",
            "        [ 1.0693, -1.9982],\n",
            "        [-3.9239,  4.5882],\n",
            "        [ 4.9392, -5.6347],\n",
            "        [ 3.8584, -5.2172],\n",
            "        [-3.9979,  4.6056],\n",
            "        [ 4.5742, -5.6197],\n",
            "        [ 4.8442, -5.6277],\n",
            "        [-4.2453,  5.0190],\n",
            "        [ 4.0535, -5.3299],\n",
            "        [-4.1142,  4.8021],\n",
            "        [ 4.6443, -5.6716],\n",
            "        [-4.0746,  4.9054],\n",
            "        [ 3.3590, -3.5302],\n",
            "        [-4.1536,  4.9613],\n",
            "        [ 4.3441, -5.1381],\n",
            "        [-4.0704,  4.8657],\n",
            "        [-4.1551,  4.9524],\n",
            "        [-2.8545,  2.6355],\n",
            "        [-3.9127,  4.6265],\n",
            "        [-4.0881,  4.8636],\n",
            "        [ 4.4101, -5.5478],\n",
            "        [-3.8622,  4.4623],\n",
            "        [-4.0110,  4.7702],\n",
            "        [-3.9684,  4.6941],\n",
            "        [-4.1063,  4.8985],\n",
            "        [-4.1190,  4.9234],\n",
            "        [-4.0745,  4.8225],\n",
            "        [-4.1089,  4.9703]], device='cuda:0')\n",
            "tensor([[-3.4740,  3.5521],\n",
            "        [-2.7024,  2.6416],\n",
            "        [ 3.9296, -5.2486],\n",
            "        [-3.8697,  4.5303],\n",
            "        [ 4.5101, -5.2711],\n",
            "        [-3.8061,  4.3280],\n",
            "        [-3.7598,  4.1863],\n",
            "        [ 4.6056, -5.5234],\n",
            "        [-4.1997,  5.0368],\n",
            "        [-4.0992,  4.8726],\n",
            "        [-3.8092,  4.3271],\n",
            "        [ 3.7747, -4.7679],\n",
            "        [-4.0433,  4.7950],\n",
            "        [-4.2475,  5.0579],\n",
            "        [-4.0400,  4.8106],\n",
            "        [ 4.7475, -5.6277],\n",
            "        [-3.1296,  3.1324],\n",
            "        [ 3.8870, -5.1795],\n",
            "        [-2.4728,  2.3107],\n",
            "        [-4.0970,  4.8450],\n",
            "        [ 0.4065, -1.0356],\n",
            "        [ 2.8840, -2.8889],\n",
            "        [-2.6742,  2.5011],\n",
            "        [ 3.6203, -3.8451],\n",
            "        [ 4.7060, -5.6039],\n",
            "        [-3.7065,  4.2184],\n",
            "        [-4.1153,  4.9016],\n",
            "        [ 3.5753, -4.2872],\n",
            "        [ 3.9459, -4.5275],\n",
            "        [-3.9492,  4.5481],\n",
            "        [-4.1462,  4.8987],\n",
            "        [-3.9933,  4.7285]], device='cuda:0')\n",
            "tensor([[ 4.7493, -5.4823],\n",
            "        [ 4.0334, -4.4882],\n",
            "        [-4.1145,  4.9033],\n",
            "        [ 3.8669, -4.5356],\n",
            "        [ 0.5241, -1.2522],\n",
            "        [-4.1575,  4.9660],\n",
            "        [ 1.1546, -2.0710],\n",
            "        [-3.3289,  3.3768],\n",
            "        [ 4.3621, -5.3389],\n",
            "        [ 3.4523, -4.0699],\n",
            "        [ 4.1217, -4.8852],\n",
            "        [ 4.4115, -5.0205],\n",
            "        [ 4.7566, -5.5488],\n",
            "        [-3.9284,  4.5378],\n",
            "        [-3.9775,  4.7392],\n",
            "        [ 4.3419, -4.6479],\n",
            "        [ 4.9490, -5.6495],\n",
            "        [ 4.5760, -5.3411],\n",
            "        [ 4.6552, -5.5175],\n",
            "        [-3.8086,  4.1907],\n",
            "        [ 3.2403, -4.1053],\n",
            "        [ 3.0682, -3.1452],\n",
            "        [ 4.6705, -5.6861],\n",
            "        [ 4.7962, -5.5034],\n",
            "        [ 3.2225, -3.6424],\n",
            "        [-3.7912,  4.3350],\n",
            "        [-4.1297,  4.9210],\n",
            "        [ 4.7637, -5.4864],\n",
            "        [-3.9391,  4.6087],\n",
            "        [ 2.2174, -2.8549],\n",
            "        [-4.1373,  4.9064],\n",
            "        [ 4.6794, -5.3698]], device='cuda:0')\n",
            "tensor([[ 3.7392, -4.8967],\n",
            "        [ 4.8892, -5.6873],\n",
            "        [ 4.6591, -5.6300],\n",
            "        [-4.1502,  4.9898],\n",
            "        [-4.2352,  5.0245],\n",
            "        [-4.1661,  4.9816],\n",
            "        [ 3.2652, -3.4459],\n",
            "        [ 4.1072, -4.4758],\n",
            "        [ 4.3601, -5.1009],\n",
            "        [-3.8969,  4.5567],\n",
            "        [ 4.3414, -5.4761],\n",
            "        [ 2.6142, -2.8919],\n",
            "        [-4.1601,  4.9444],\n",
            "        [ 4.7855, -5.6026],\n",
            "        [-2.0717,  1.8184],\n",
            "        [-4.1079,  4.8919],\n",
            "        [ 4.2827, -5.4403],\n",
            "        [ 4.6671, -5.6175],\n",
            "        [ 2.4201, -2.6143],\n",
            "        [ 4.3017, -5.5271],\n",
            "        [ 4.1154, -4.6733],\n",
            "        [-3.8258,  4.2613],\n",
            "        [-3.3851,  3.4313],\n",
            "        [ 3.5697, -4.5628],\n",
            "        [ 4.8327, -5.6036],\n",
            "        [ 4.7011, -5.6655],\n",
            "        [-4.0543,  4.8120],\n",
            "        [ 4.2897, -5.1628],\n",
            "        [-3.9127,  4.4807],\n",
            "        [-4.0089,  4.7536],\n",
            "        [ 4.4904, -5.5779],\n",
            "        [-1.7048,  1.2492]], device='cuda:0')\n",
            "tensor([[-4.1543,  4.9820],\n",
            "        [ 4.4628, -5.4564],\n",
            "        [-4.0934,  4.8378],\n",
            "        [ 4.1433, -4.2170],\n",
            "        [-4.1125,  4.8910],\n",
            "        [ 4.1594, -5.1322],\n",
            "        [ 4.1367, -5.0646],\n",
            "        [-3.9874,  4.7651],\n",
            "        [ 2.7098, -2.9173],\n",
            "        [-3.7097,  4.1586],\n",
            "        [-3.6061,  3.9647],\n",
            "        [ 4.4460, -5.1928],\n",
            "        [-4.0729,  4.7711],\n",
            "        [-4.1754,  4.9520],\n",
            "        [ 4.9642, -5.5691],\n",
            "        [-4.1698,  5.0032],\n",
            "        [-4.2043,  5.0402],\n",
            "        [-4.0258,  4.7124],\n",
            "        [-4.1584,  4.9279],\n",
            "        [ 2.0226, -2.4301],\n",
            "        [ 4.2487, -4.9627],\n",
            "        [ 4.4161, -4.9982],\n",
            "        [ 4.8436, -5.3567],\n",
            "        [ 4.7008, -5.6512],\n",
            "        [ 4.2219, -4.8539],\n",
            "        [-4.0333,  4.7831],\n",
            "        [-3.8183,  4.2931],\n",
            "        [-4.0252,  4.7493],\n",
            "        [-2.7972,  2.7823],\n",
            "        [-4.1307,  4.9396],\n",
            "        [ 4.5835, -5.1349],\n",
            "        [ 4.3090, -4.8792]], device='cuda:0')\n",
            "tensor([[-4.1491,  4.9729],\n",
            "        [ 4.6680, -5.2937],\n",
            "        [ 3.6974, -3.3207],\n",
            "        [-4.1642,  4.9789],\n",
            "        [-4.0899,  4.8890],\n",
            "        [-4.1390,  4.9402],\n",
            "        [-4.1719,  4.9953],\n",
            "        [ 4.2568, -5.4193],\n",
            "        [ 4.7793, -5.3386],\n",
            "        [-4.1322,  4.9845],\n",
            "        [ 4.4477, -5.2313],\n",
            "        [-4.0732,  4.8951],\n",
            "        [-1.2084,  0.7607],\n",
            "        [-3.8802,  4.3705],\n",
            "        [ 3.9858, -4.3983],\n",
            "        [ 4.5307, -5.3738],\n",
            "        [-4.1504,  4.9299],\n",
            "        [ 4.1998, -5.1764],\n",
            "        [ 4.9728, -5.4937],\n",
            "        [ 4.9565, -5.5075],\n",
            "        [-4.1201,  4.9325],\n",
            "        [ 4.1096, -4.5522],\n",
            "        [ 4.5514, -5.5556],\n",
            "        [-4.2141,  5.0091],\n",
            "        [ 4.1987, -5.1869],\n",
            "        [ 4.3385, -5.0196],\n",
            "        [-4.1461,  4.9317],\n",
            "        [-4.0393,  4.7525],\n",
            "        [ 3.8980, -4.3784],\n",
            "        [ 3.6871, -4.0420],\n",
            "        [-2.3361,  1.9931],\n",
            "        [ 4.8919, -5.6114]], device='cuda:0')\n",
            "tensor([[ 1.3964, -2.2299],\n",
            "        [-3.7588,  4.3642],\n",
            "        [ 3.9829, -4.1844],\n",
            "        [ 4.7845, -5.4344],\n",
            "        [ 4.4096, -5.0888],\n",
            "        [-4.1463,  4.9191],\n",
            "        [ 4.2336, -5.4562],\n",
            "        [ 4.2512, -5.4828],\n",
            "        [ 4.6533, -5.5084],\n",
            "        [ 4.4562, -5.6002],\n",
            "        [-3.8209,  4.5814],\n",
            "        [-4.2102,  5.0208],\n",
            "        [ 4.9216, -5.5711],\n",
            "        [-3.8275,  4.3314],\n",
            "        [ 4.5260, -5.2279],\n",
            "        [-4.0388,  4.8498],\n",
            "        [ 4.7594, -5.4120],\n",
            "        [-4.0739,  4.8171],\n",
            "        [ 4.2709, -4.8682],\n",
            "        [ 4.3473, -4.7095],\n",
            "        [ 2.9662, -2.9975],\n",
            "        [-4.1841,  4.9904],\n",
            "        [ 4.5107, -5.6237],\n",
            "        [ 2.2254, -2.6934],\n",
            "        [ 4.7680, -5.6634],\n",
            "        [-4.0686,  4.9050],\n",
            "        [ 4.6123, -5.4066],\n",
            "        [-4.0806,  4.8392],\n",
            "        [-3.6857,  3.9856],\n",
            "        [-4.1512,  4.9090],\n",
            "        [ 4.6165, -5.5304],\n",
            "        [-4.0904,  4.8089]], device='cuda:0')\n",
            "tensor([[ 4.6039, -5.6282],\n",
            "        [ 5.0240, -5.5941],\n",
            "        [ 4.6699, -5.6752],\n",
            "        [-4.0570,  4.8154],\n",
            "        [ 4.5440, -5.5463],\n",
            "        [ 4.4989, -5.1681],\n",
            "        [ 4.6980, -5.3374],\n",
            "        [ 4.8104, -5.6927],\n",
            "        [-4.0491,  4.7931],\n",
            "        [ 4.8406, -5.4423],\n",
            "        [ 3.9035, -4.6580],\n",
            "        [-3.6643,  3.8920],\n",
            "        [ 2.6637, -2.8582],\n",
            "        [-4.0672,  4.8516],\n",
            "        [-4.1525,  4.9115],\n",
            "        [-3.9106,  4.6071],\n",
            "        [-4.1371,  4.9393],\n",
            "        [-3.8743,  4.5157],\n",
            "        [ 3.8343, -4.4679],\n",
            "        [-4.0812,  4.8674],\n",
            "        [ 3.3658, -3.7328],\n",
            "        [-3.2209,  3.1295],\n",
            "        [ 4.6686, -5.6159],\n",
            "        [ 4.6496, -5.3747],\n",
            "        [ 2.2958, -2.7263],\n",
            "        [ 4.3221, -5.3261],\n",
            "        [ 4.1701, -4.8501],\n",
            "        [-3.9203,  4.6083],\n",
            "        [-4.0237,  4.8201],\n",
            "        [-4.0430,  4.7240],\n",
            "        [-4.1424,  4.9532],\n",
            "        [-4.0255,  4.7154]], device='cuda:0')\n",
            "tensor([[-4.0668,  4.8613],\n",
            "        [ 1.3199, -2.1819],\n",
            "        [-4.0588,  4.8924],\n",
            "        [-4.1458,  4.8925],\n",
            "        [-4.1697,  4.9611],\n",
            "        [ 4.1076, -4.2823],\n",
            "        [-4.0600,  4.7919],\n",
            "        [ 4.5672, -5.3343],\n",
            "        [-4.1921,  5.0266],\n",
            "        [ 0.1269, -0.5299],\n",
            "        [-3.5767,  3.8069],\n",
            "        [ 2.8602, -3.0734],\n",
            "        [ 3.5229, -3.7112],\n",
            "        [ 3.6240, -3.6782],\n",
            "        [-4.2930,  5.0640],\n",
            "        [ 3.7823, -5.0323],\n",
            "        [ 3.8662, -3.8885],\n",
            "        [-4.0636,  4.8698],\n",
            "        [ 2.8036, -3.1666],\n",
            "        [-4.0635,  4.7756],\n",
            "        [-4.0492,  4.7120],\n",
            "        [ 4.0441, -4.1990],\n",
            "        [ 3.5719, -4.5468],\n",
            "        [ 3.5800, -3.7232],\n",
            "        [ 4.9530, -5.4600],\n",
            "        [ 3.9168, -4.8695],\n",
            "        [-4.1376,  4.8619],\n",
            "        [ 4.9608, -5.5940],\n",
            "        [ 4.4258, -5.2208],\n",
            "        [ 4.3596, -5.5823],\n",
            "        [ 3.4620, -4.2410],\n",
            "        [-4.1534,  4.9344]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:  34%|███▍      | 11/32 [00:00<00:00, 37.03it/s]\u001b[A\n",
            "Test:  50%|█████     | 16/32 [00:00<00:00, 41.51it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.3093, -5.2220],\n",
            "        [-4.1934,  5.0089],\n",
            "        [-4.0345,  4.7642],\n",
            "        [-0.6124,  0.0973],\n",
            "        [ 4.7942, -5.5321],\n",
            "        [ 2.9214, -2.9764],\n",
            "        [ 4.4112, -5.3555],\n",
            "        [-4.1086,  4.9095],\n",
            "        [-4.1280,  4.9297],\n",
            "        [-4.1767,  5.0070],\n",
            "        [ 4.2931, -5.1931],\n",
            "        [-4.0538,  4.7886],\n",
            "        [-3.9356,  4.6972],\n",
            "        [-4.2312,  4.9792],\n",
            "        [-4.0821,  4.9382],\n",
            "        [-4.1379,  4.9256],\n",
            "        [-4.2348,  5.0180],\n",
            "        [-3.6898,  4.1131],\n",
            "        [-4.1969,  5.0058],\n",
            "        [-4.1753,  4.9242],\n",
            "        [-4.0162,  4.7428],\n",
            "        [-4.0649,  4.7604],\n",
            "        [-4.1073,  4.9001],\n",
            "        [-4.0784,  4.7607],\n",
            "        [-4.1152,  4.8748],\n",
            "        [ 4.4368, -5.5906],\n",
            "        [-4.0168,  4.6774],\n",
            "        [ 3.2657, -4.3724],\n",
            "        [-0.3866, -0.0301],\n",
            "        [ 4.6973, -5.5008],\n",
            "        [ 5.0266, -5.6281],\n",
            "        [-2.2393,  2.0588]], device='cuda:0')\n",
            "tensor([[ 4.5063, -5.6436],\n",
            "        [-4.0415,  4.8646],\n",
            "        [-4.2162,  5.0218],\n",
            "        [ 2.0264, -2.6890],\n",
            "        [ 4.0243, -4.5500],\n",
            "        [-0.5903,  0.1071],\n",
            "        [-4.0887,  4.8391],\n",
            "        [ 4.5821, -5.1212],\n",
            "        [ 2.6330, -2.8522],\n",
            "        [-4.0706,  4.8146],\n",
            "        [-4.0950,  4.8844],\n",
            "        [-1.1257,  0.6667],\n",
            "        [ 4.0561, -4.4779],\n",
            "        [-4.1386,  4.9471],\n",
            "        [-3.9641,  4.6838],\n",
            "        [-4.1681,  4.9406],\n",
            "        [ 4.3666, -5.3486],\n",
            "        [-0.2397, -0.2799],\n",
            "        [ 4.9607, -5.6106],\n",
            "        [ 4.7286, -5.4055],\n",
            "        [ 4.7253, -5.3683],\n",
            "        [ 4.5423, -5.2648],\n",
            "        [ 4.3152, -5.2019],\n",
            "        [ 1.3205, -2.1769],\n",
            "        [-4.2216,  5.0084],\n",
            "        [-4.1882,  4.9567],\n",
            "        [-4.1779,  4.9911],\n",
            "        [ 4.6976, -5.6486],\n",
            "        [-3.9673,  4.7502],\n",
            "        [-4.1515,  4.9693],\n",
            "        [-4.0466,  4.8757],\n",
            "        [-4.1484,  4.9641]], device='cuda:0')\n",
            "tensor([[ 3.3178, -3.3507],\n",
            "        [-4.0650,  4.8061],\n",
            "        [ 4.2353, -5.1592],\n",
            "        [ 4.5591, -5.4432],\n",
            "        [-4.0352,  4.7628],\n",
            "        [-3.9279,  4.4930],\n",
            "        [-4.0408,  4.8283],\n",
            "        [ 4.9233, -5.6797],\n",
            "        [-4.1399,  4.9374],\n",
            "        [-4.0609,  4.8738],\n",
            "        [ 4.3717, -5.0648],\n",
            "        [ 4.2574, -5.3584],\n",
            "        [ 0.3916, -1.1755],\n",
            "        [-4.0764,  4.8865],\n",
            "        [-3.8839,  4.4883],\n",
            "        [-4.0866,  4.8981],\n",
            "        [ 3.5945, -3.5769],\n",
            "        [ 4.6273, -5.4770],\n",
            "        [ 4.1058, -4.6909],\n",
            "        [-4.1012,  4.8714],\n",
            "        [-4.1942,  4.9896],\n",
            "        [-3.9503,  4.6415],\n",
            "        [-2.7838,  2.7553],\n",
            "        [ 1.1757, -2.0395],\n",
            "        [-4.0168,  4.7852],\n",
            "        [ 0.2805, -0.7428],\n",
            "        [-3.9316,  4.5497],\n",
            "        [ 4.2927, -5.2260],\n",
            "        [-4.0148,  4.7739],\n",
            "        [-3.9661,  4.6701],\n",
            "        [-3.8086,  4.3385],\n",
            "        [ 3.3529, -3.9898]], device='cuda:0')\n",
            "tensor([[-0.7287,  0.3009],\n",
            "        [-4.1432,  4.9754],\n",
            "        [-3.9542,  4.6617],\n",
            "        [ 1.5318, -2.2823],\n",
            "        [-4.0480,  4.7712],\n",
            "        [-4.0805,  4.8624],\n",
            "        [ 4.8762, -5.6763],\n",
            "        [ 2.6469, -3.0449],\n",
            "        [-3.8919,  4.5356],\n",
            "        [ 3.8836, -4.5323],\n",
            "        [-4.1527,  4.9876],\n",
            "        [ 4.5760, -5.4113],\n",
            "        [-2.4762,  2.0612],\n",
            "        [-3.8966,  4.5567],\n",
            "        [-4.0569,  4.8268],\n",
            "        [-3.9631,  4.7250],\n",
            "        [-4.1614,  4.9333],\n",
            "        [-4.0090,  4.7143],\n",
            "        [ 4.4091, -5.4355],\n",
            "        [ 3.7293, -4.2685],\n",
            "        [-3.0597,  3.1283],\n",
            "        [-4.0623,  4.7880],\n",
            "        [ 4.3604, -5.0558],\n",
            "        [ 4.4764, -5.6160],\n",
            "        [ 4.4320, -5.4971],\n",
            "        [ 3.6801, -3.6541],\n",
            "        [ 3.9360, -4.5432],\n",
            "        [ 4.2611, -4.9777],\n",
            "        [ 4.6981, -5.4745],\n",
            "        [-3.9641,  4.7014],\n",
            "        [ 4.7643, -5.5665],\n",
            "        [-4.0650,  4.8987]], device='cuda:0')\n",
            "tensor([[ 4.5576, -5.2785],\n",
            "        [-3.1892,  3.1039],\n",
            "        [-4.2099,  4.9821],\n",
            "        [-4.0312,  4.7865],\n",
            "        [ 4.7896, -5.5241],\n",
            "        [-3.9841,  4.6978],\n",
            "        [-3.3473,  3.5036],\n",
            "        [-4.0899,  4.9224],\n",
            "        [ 2.5078, -3.1058],\n",
            "        [-4.1764,  4.9843],\n",
            "        [ 4.0214, -5.2401],\n",
            "        [ 4.0677, -4.8235],\n",
            "        [-4.0929,  4.8796],\n",
            "        [ 3.8234, -3.8733],\n",
            "        [ 4.6026, -5.4083],\n",
            "        [-4.1856,  4.9583],\n",
            "        [-4.1753,  4.9735],\n",
            "        [-4.0510,  4.8756],\n",
            "        [ 3.3385, -3.7852],\n",
            "        [ 4.6745, -5.4862],\n",
            "        [-4.1670,  4.9906],\n",
            "        [ 4.6484, -5.4434],\n",
            "        [ 4.1960, -4.7577],\n",
            "        [ 4.4943, -5.4678],\n",
            "        [ 4.6843, -5.4367],\n",
            "        [ 3.5684, -3.8889],\n",
            "        [ 4.8658, -5.5965],\n",
            "        [ 4.5333, -5.4918],\n",
            "        [-4.1188,  4.9500],\n",
            "        [-3.7659,  4.2334],\n",
            "        [-4.1532,  4.9352],\n",
            "        [-4.1622,  4.9596]], device='cuda:0')\n",
            "tensor([[-4.1952,  4.9478],\n",
            "        [-3.8213,  4.2918],\n",
            "        [-4.1536,  4.9664],\n",
            "        [-3.9137,  4.5995],\n",
            "        [-3.6624,  3.8737],\n",
            "        [-4.1476,  4.9375],\n",
            "        [-3.9844,  4.7081],\n",
            "        [-4.0663,  4.8690],\n",
            "        [ 4.2139, -4.5538],\n",
            "        [ 0.3947, -0.9699],\n",
            "        [ 4.1671, -4.9501],\n",
            "        [ 4.4495, -5.4324],\n",
            "        [-3.6499,  4.0967],\n",
            "        [-3.9664,  4.7334],\n",
            "        [-4.0827,  4.8527],\n",
            "        [ 4.8583, -5.6102],\n",
            "        [-3.7915,  4.2485],\n",
            "        [ 4.2158, -5.0427],\n",
            "        [ 4.2390, -4.6544],\n",
            "        [-3.5784,  4.0222],\n",
            "        [ 4.6723, -5.3894],\n",
            "        [ 4.6358, -5.6025],\n",
            "        [ 3.0796, -3.5541],\n",
            "        [ 0.7432, -1.5984],\n",
            "        [ 2.6543, -2.8027],\n",
            "        [ 4.7615, -5.6285],\n",
            "        [ 4.4768, -5.2233],\n",
            "        [ 3.6195, -3.4686],\n",
            "        [ 2.0689, -2.6259],\n",
            "        [ 4.5548, -5.2248],\n",
            "        [ 4.1238, -5.3136],\n",
            "        [-4.0146,  4.6546]], device='cuda:0')\n",
            "tensor([[-4.1254,  4.9656],\n",
            "        [ 4.6693, -5.4657],\n",
            "        [ 3.9477, -4.6120],\n",
            "        [-4.0973,  4.8927],\n",
            "        [-0.8966,  0.4021],\n",
            "        [-4.0486,  4.8776],\n",
            "        [-4.0551,  4.7965],\n",
            "        [ 4.7304, -5.6772],\n",
            "        [-4.1360,  4.9423],\n",
            "        [-4.1333,  4.9517],\n",
            "        [-4.0608,  4.7939],\n",
            "        [-2.9362,  2.8650],\n",
            "        [ 4.7693, -5.5154],\n",
            "        [ 4.2007, -4.7788],\n",
            "        [-2.2370,  1.9961],\n",
            "        [ 4.2713, -5.4708],\n",
            "        [-4.1319,  4.9213],\n",
            "        [-4.1605,  4.9490],\n",
            "        [ 4.6513, -5.6185],\n",
            "        [ 4.1407, -5.4440],\n",
            "        [ 2.2473, -3.0565],\n",
            "        [-4.0427,  4.8121],\n",
            "        [-2.7993,  2.6199],\n",
            "        [-4.2352,  5.0087],\n",
            "        [ 4.8616, -5.6784],\n",
            "        [ 4.6167, -4.9929],\n",
            "        [-4.1364,  4.9051],\n",
            "        [-4.1421,  4.9884],\n",
            "        [-4.1506,  4.9491],\n",
            "        [-4.1048,  4.8398],\n",
            "        [ 4.8189, -5.5296],\n",
            "        [-1.2987,  0.7601]], device='cuda:0')\n",
            "tensor([[-3.7021,  3.9478],\n",
            "        [-3.9340,  4.5780],\n",
            "        [-3.9569,  4.6891],\n",
            "        [-4.1651,  4.9215],\n",
            "        [-4.0360,  4.8888],\n",
            "        [-4.1055,  4.7912],\n",
            "        [-3.6366,  4.0117],\n",
            "        [-3.7055,  4.0304],\n",
            "        [-2.3435,  1.9088],\n",
            "        [ 4.9045, -5.5506],\n",
            "        [-4.0911,  4.7128],\n",
            "        [-4.0903,  4.9052],\n",
            "        [-4.0376,  4.8093],\n",
            "        [ 3.9969, -4.7671],\n",
            "        [-4.1254,  4.9449],\n",
            "        [ 3.7100, -4.7546],\n",
            "        [ 4.6715, -5.2225],\n",
            "        [-3.5390,  3.6898],\n",
            "        [-3.9096,  4.4798],\n",
            "        [-4.0566,  4.6759],\n",
            "        [-4.1074,  4.8507],\n",
            "        [ 3.4860, -4.4208],\n",
            "        [-3.9635,  4.6978],\n",
            "        [-3.9526,  4.6501],\n",
            "        [-4.1957,  4.9919],\n",
            "        [ 4.1871, -5.2675],\n",
            "        [ 3.4965, -3.2193],\n",
            "        [ 4.7734, -5.6429],\n",
            "        [ 4.4018, -5.2048],\n",
            "        [-4.1700,  4.9874],\n",
            "        [-4.1449,  4.8735],\n",
            "        [-4.0579,  4.7887]], device='cuda:0')\n",
            "tensor([[ 4.8870, -5.6550],\n",
            "        [-4.0322,  4.7131],\n",
            "        [ 4.8696, -5.4219],\n",
            "        [ 5.0234, -5.4781],\n",
            "        [ 4.3047, -5.2426],\n",
            "        [-3.6936,  4.1097],\n",
            "        [ 4.6735, -5.6217],\n",
            "        [-4.0843,  4.8233],\n",
            "        [ 3.8448, -4.1563],\n",
            "        [ 3.4731, -3.5276],\n",
            "        [ 4.1851, -4.9090],\n",
            "        [ 4.7978, -5.4464],\n",
            "        [ 3.5413, -3.8943],\n",
            "        [-4.0695,  4.7831],\n",
            "        [ 4.4696, -5.2251],\n",
            "        [-4.0841,  4.8894],\n",
            "        [-4.0925,  4.8861],\n",
            "        [ 3.1168, -3.2520],\n",
            "        [ 4.4432, -5.0247],\n",
            "        [ 4.8104, -5.6858],\n",
            "        [ 4.3479, -5.5182],\n",
            "        [ 4.3283, -4.6404],\n",
            "        [-3.9672,  4.6592],\n",
            "        [ 4.7671, -5.4376],\n",
            "        [ 2.4659, -2.8806],\n",
            "        [-4.0284,  4.7442],\n",
            "        [ 2.4319, -2.5283],\n",
            "        [-3.7762,  4.3240],\n",
            "        [ 4.2447, -5.3865],\n",
            "        [-3.8458,  4.3377],\n",
            "        [ 4.6707, -5.1316],\n",
            "        [-3.5144,  3.6977]], device='cuda:0')\n",
            "tensor([[ 1.6860, -2.4372],\n",
            "        [-3.7695,  4.2171],\n",
            "        [-3.9827,  4.6277],\n",
            "        [-3.9812,  4.6372],\n",
            "        [-4.0695,  4.8681],\n",
            "        [ 3.9453, -4.3363],\n",
            "        [-4.1162,  4.8843],\n",
            "        [ 4.4868, -5.4940],\n",
            "        [-4.0010,  4.7013],\n",
            "        [ 4.5460, -5.5399],\n",
            "        [-3.9588,  4.6413],\n",
            "        [-2.9657,  3.0390],\n",
            "        [ 4.4167, -5.4248],\n",
            "        [-4.1208,  4.9045],\n",
            "        [ 3.4960, -3.4748],\n",
            "        [-4.1531,  4.9058],\n",
            "        [-4.1774,  5.0120],\n",
            "        [ 4.2044, -4.7010],\n",
            "        [-4.1201,  4.8851],\n",
            "        [ 4.1244, -4.9082],\n",
            "        [ 1.0696, -1.9439],\n",
            "        [-3.9941,  4.6728],\n",
            "        [-4.0807,  4.8203],\n",
            "        [-0.1452, -0.4546],\n",
            "        [ 4.7773, -5.4641],\n",
            "        [-4.1437,  4.9069],\n",
            "        [-2.9065,  2.8572],\n",
            "        [ 4.3814, -5.0623],\n",
            "        [-1.4274,  1.2122],\n",
            "        [ 4.9714, -5.5487],\n",
            "        [ 4.6662, -5.6990],\n",
            "        [ 4.9172, -5.5009]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:  66%|██████▌   | 21/32 [00:00<00:00, 44.18it/s]\u001b[A\n",
            "Test:  81%|████████▏ | 26/32 [00:00<00:00, 45.39it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.0385, -3.0550],\n",
            "        [-4.0229,  4.7323],\n",
            "        [ 4.7143, -5.5994],\n",
            "        [ 4.4906, -5.2527],\n",
            "        [ 4.4339, -5.2050],\n",
            "        [ 3.8213, -4.4639],\n",
            "        [-3.9491,  4.6674],\n",
            "        [ 4.5020, -5.6251],\n",
            "        [-3.1958,  3.1180],\n",
            "        [ 3.4288, -3.6215],\n",
            "        [-3.9858,  4.8087],\n",
            "        [ 2.4010, -2.9890],\n",
            "        [ 3.0715, -3.1603],\n",
            "        [-4.1280,  4.9209],\n",
            "        [ 4.5155, -5.1568],\n",
            "        [ 1.4879, -2.3618],\n",
            "        [-4.0767,  4.8532],\n",
            "        [-4.1532,  4.9555],\n",
            "        [-3.8499,  4.3590],\n",
            "        [ 4.8325, -5.6132],\n",
            "        [-4.0898,  4.8915],\n",
            "        [ 4.3016, -4.7750],\n",
            "        [ 3.7137, -4.3031],\n",
            "        [ 4.9321, -5.6146],\n",
            "        [-4.1486,  4.9444],\n",
            "        [ 4.5765, -5.2184],\n",
            "        [ 4.7622, -5.4929],\n",
            "        [ 4.4387, -5.2427],\n",
            "        [ 4.4856, -5.3286],\n",
            "        [-3.8734,  4.4735],\n",
            "        [ 2.8103, -2.5848],\n",
            "        [ 4.3238, -5.1262]], device='cuda:0')\n",
            "tensor([[ 4.0046, -4.5285],\n",
            "        [ 3.8457, -5.1659],\n",
            "        [ 4.7429, -5.5906],\n",
            "        [ 4.0640, -5.2216],\n",
            "        [-4.1648,  4.9644],\n",
            "        [ 4.7803, -5.6573],\n",
            "        [ 4.4378, -5.2465],\n",
            "        [ 4.8486, -5.4281],\n",
            "        [ 4.7156, -5.5929],\n",
            "        [-3.8977,  4.5033],\n",
            "        [ 3.4669, -4.3851],\n",
            "        [-4.0131,  4.7973],\n",
            "        [ 3.5257, -4.8638],\n",
            "        [ 4.8910, -5.6347],\n",
            "        [-4.1222,  4.9456],\n",
            "        [-2.7863,  2.6166],\n",
            "        [-4.0655,  4.6884],\n",
            "        [ 4.2500, -5.3371],\n",
            "        [-4.1978,  4.9606],\n",
            "        [ 4.5910, -5.5012],\n",
            "        [ 4.8782, -5.5202],\n",
            "        [ 4.6397, -5.3868],\n",
            "        [-3.6693,  4.2255],\n",
            "        [ 3.8625, -5.1834],\n",
            "        [ 4.8944, -5.5419],\n",
            "        [ 4.3620, -5.0454],\n",
            "        [-2.9859,  2.8901],\n",
            "        [ 4.7009, -5.3000],\n",
            "        [-4.2146,  5.0111],\n",
            "        [ 4.7093, -5.2141],\n",
            "        [ 4.7666, -5.6873],\n",
            "        [-3.9518,  4.5742]], device='cuda:0')\n",
            "tensor([[ 4.6803, -5.6945],\n",
            "        [ 3.4151, -3.5088],\n",
            "        [ 3.6458, -3.2611],\n",
            "        [ 4.1849, -5.0579],\n",
            "        [-2.5100,  2.3611],\n",
            "        [-4.0758,  4.8314],\n",
            "        [ 4.4763, -5.0996],\n",
            "        [-3.6596,  4.2315],\n",
            "        [ 4.5048, -5.1494],\n",
            "        [-4.1379,  4.9024],\n",
            "        [-4.0890,  4.8931],\n",
            "        [-3.3739,  3.6642],\n",
            "        [-4.0984,  4.8837],\n",
            "        [ 4.6764, -5.6908],\n",
            "        [-4.0395,  4.8676],\n",
            "        [ 4.0703, -5.4073],\n",
            "        [-3.9406,  4.5532],\n",
            "        [ 3.4547, -3.3074],\n",
            "        [ 3.5333, -4.5327],\n",
            "        [-4.1301,  4.9546],\n",
            "        [-4.2255,  4.9796],\n",
            "        [-4.1675,  4.9932],\n",
            "        [-3.2834,  3.3719],\n",
            "        [ 3.8169, -4.4784],\n",
            "        [ 3.5242, -4.5332],\n",
            "        [-4.1031,  4.9791],\n",
            "        [-4.0922,  4.8378],\n",
            "        [-3.6758,  4.0431],\n",
            "        [-4.1737,  4.9655],\n",
            "        [ 4.3089, -5.0932],\n",
            "        [-4.1571,  4.9131],\n",
            "        [-4.1654,  4.9637]], device='cuda:0')\n",
            "tensor([[-4.1357,  4.9690],\n",
            "        [-3.9240,  4.5801],\n",
            "        [-2.6004,  2.4042],\n",
            "        [-4.0707,  4.8984],\n",
            "        [-2.4133,  2.2037],\n",
            "        [ 3.2625, -3.2920],\n",
            "        [-2.4646,  2.1945],\n",
            "        [ 3.8866, -4.5397],\n",
            "        [-3.9181,  4.6928],\n",
            "        [ 3.6296, -5.1195],\n",
            "        [ 4.0388, -4.4670],\n",
            "        [-4.0548,  4.8055],\n",
            "        [ 4.3738, -5.3320],\n",
            "        [-4.1857,  4.9873],\n",
            "        [-3.9752,  4.6425],\n",
            "        [-4.1214,  4.9656],\n",
            "        [-4.0069,  4.7953],\n",
            "        [ 4.3499, -5.2444],\n",
            "        [ 4.5145, -5.1711],\n",
            "        [ 4.6050, -5.5302],\n",
            "        [-4.1009,  4.9374],\n",
            "        [-3.8682,  4.4482],\n",
            "        [-4.0939,  4.9068],\n",
            "        [ 4.3001, -4.7819],\n",
            "        [-2.5269,  2.3471],\n",
            "        [ 4.3981, -4.8546],\n",
            "        [-4.1951,  5.0052],\n",
            "        [ 4.2956, -5.4120],\n",
            "        [-4.0585,  4.8107],\n",
            "        [ 4.4781, -5.4029],\n",
            "        [ 2.5786, -2.6470],\n",
            "        [-3.9258,  4.6676]], device='cuda:0')\n",
            "tensor([[ 4.8412, -5.5804],\n",
            "        [ 4.8022, -5.6576],\n",
            "        [ 0.3073, -0.9554],\n",
            "        [ 4.7239, -5.6945],\n",
            "        [ 2.9832, -3.1046],\n",
            "        [ 4.5481, -5.1289],\n",
            "        [ 4.6125, -5.5529],\n",
            "        [ 4.3507, -5.2595],\n",
            "        [ 4.6761, -5.5230],\n",
            "        [-4.0171,  4.8105],\n",
            "        [ 3.8572, -4.2668],\n",
            "        [-3.9882,  4.6495],\n",
            "        [-3.9813,  4.5805],\n",
            "        [ 3.7348, -3.6272],\n",
            "        [ 4.4232, -5.5289],\n",
            "        [-4.1404,  4.9576],\n",
            "        [-3.9271,  4.6870],\n",
            "        [ 4.6591, -5.1519],\n",
            "        [ 0.9914, -1.8678],\n",
            "        [-3.5212,  3.7683],\n",
            "        [-4.0684,  4.8171],\n",
            "        [-4.0685,  4.8525],\n",
            "        [-4.1885,  4.9824],\n",
            "        [-4.1002,  4.9345],\n",
            "        [-4.1393,  4.9567],\n",
            "        [-4.0882,  4.8377],\n",
            "        [ 4.1606, -4.7467],\n",
            "        [ 4.7026, -5.4224],\n",
            "        [ 3.7003, -4.2077],\n",
            "        [ 4.5271, -5.0791],\n",
            "        [ 4.6116, -5.4253],\n",
            "        [ 4.9332, -5.4519]], device='cuda:0')\n",
            "tensor([[-4.0765,  4.8244],\n",
            "        [ 3.6803, -4.2360],\n",
            "        [-4.1860,  4.8667],\n",
            "        [ 4.4228, -4.9323],\n",
            "        [ 4.6612, -5.3649],\n",
            "        [-4.1959,  4.9981],\n",
            "        [ 4.0858, -5.2806],\n",
            "        [ 4.4287, -5.5050],\n",
            "        [-3.9375,  4.5436],\n",
            "        [ 4.7719, -5.6639],\n",
            "        [-4.1580,  5.0006],\n",
            "        [-4.0211,  4.8109],\n",
            "        [ 3.8743, -4.4159],\n",
            "        [-4.1271,  4.9116],\n",
            "        [-3.9707,  4.5949],\n",
            "        [ 4.6896, -5.3595],\n",
            "        [-4.1275,  4.9668],\n",
            "        [ 2.8949, -2.9887],\n",
            "        [ 4.5771, -5.3480],\n",
            "        [-3.9504,  4.5369],\n",
            "        [-4.2047,  5.0032],\n",
            "        [-4.2312,  4.9779],\n",
            "        [-4.0186,  4.7368],\n",
            "        [-4.0779,  4.8434],\n",
            "        [-2.5150,  2.3515],\n",
            "        [-4.1200,  4.8765],\n",
            "        [-4.1626,  4.8652],\n",
            "        [-4.1859,  4.9943],\n",
            "        [-4.1844,  5.0068],\n",
            "        [ 4.4824, -5.2076],\n",
            "        [-3.4380,  3.5963],\n",
            "        [ 4.6577, -5.6198]], device='cuda:0')\n",
            "tensor([[-4.0809,  4.7902],\n",
            "        [ 3.6163, -3.1499],\n",
            "        [ 1.4954, -2.0522],\n",
            "        [ 4.4267, -5.2608],\n",
            "        [-4.0335,  4.7455],\n",
            "        [ 2.4958, -3.2197],\n",
            "        [ 4.2082, -5.2544],\n",
            "        [-4.0689,  4.9123],\n",
            "        [ 3.7847, -4.2187],\n",
            "        [ 4.1632, -5.2339],\n",
            "        [ 3.7670, -4.8141],\n",
            "        [-4.0389,  4.7689],\n",
            "        [ 3.3054, -4.1118],\n",
            "        [ 4.0647, -4.8702],\n",
            "        [ 4.5322, -5.4729],\n",
            "        [ 2.1107, -2.6250],\n",
            "        [ 3.9394, -4.5320],\n",
            "        [-3.8670,  4.3207],\n",
            "        [ 4.6568, -5.2697],\n",
            "        [-3.9042,  4.5534],\n",
            "        [-4.0483,  4.7768],\n",
            "        [ 4.3661, -4.9910],\n",
            "        [ 3.9328, -4.4872],\n",
            "        [ 4.2839, -4.9253],\n",
            "        [ 4.2410, -5.3079],\n",
            "        [-4.0051,  4.6544],\n",
            "        [ 3.4925, -3.7543],\n",
            "        [ 3.8878, -4.0873],\n",
            "        [-4.2396,  5.0566],\n",
            "        [ 3.8332, -4.2605],\n",
            "        [-4.0922,  4.9318],\n",
            "        [ 4.0645, -4.9140]], device='cuda:0')\n",
            "tensor([[ 3.2709, -3.6244],\n",
            "        [-4.0352,  4.7670],\n",
            "        [-4.0870,  4.8630],\n",
            "        [-4.1199,  4.9261],\n",
            "        [-4.0814,  4.8984],\n",
            "        [-4.1950,  4.9938],\n",
            "        [-3.8061,  4.3273],\n",
            "        [ 4.8282, -5.5991],\n",
            "        [-4.1120,  4.8857],\n",
            "        [ 4.2688, -5.2680],\n",
            "        [-4.0475,  4.8083],\n",
            "        [-3.4549,  3.5281],\n",
            "        [-4.1789,  4.9605],\n",
            "        [-3.6755,  4.2053],\n",
            "        [ 4.6836, -5.5497],\n",
            "        [ 1.1783, -2.1049],\n",
            "        [-4.1701,  4.9260],\n",
            "        [ 4.8326, -5.5509],\n",
            "        [-3.6251,  3.9644],\n",
            "        [ 4.6425, -5.3086],\n",
            "        [ 4.0148, -4.7036],\n",
            "        [-3.8170,  4.3414],\n",
            "        [ 3.9598, -5.2630],\n",
            "        [ 4.9129, -5.5349],\n",
            "        [-3.7562,  4.2803],\n",
            "        [-3.7960,  4.4417],\n",
            "        [ 4.4422, -5.0580],\n",
            "        [ 3.5844, -3.7936],\n",
            "        [ 2.9558, -3.7397],\n",
            "        [ 4.6860, -5.6429],\n",
            "        [-4.0554,  4.8436],\n",
            "        [-3.4586,  3.8442]], device='cuda:0')\n",
            "tensor([[-4.0277,  4.7743],\n",
            "        [ 4.3341, -5.5328],\n",
            "        [-1.4907,  1.1681],\n",
            "        [-4.0520,  4.8565],\n",
            "        [ 4.5852, -5.2149],\n",
            "        [-4.1355,  4.9025],\n",
            "        [-1.9240,  1.6963],\n",
            "        [-4.0556,  4.8487],\n",
            "        [-3.9462,  4.6863],\n",
            "        [-4.1695,  4.9887],\n",
            "        [ 3.4396, -3.4985],\n",
            "        [ 3.6157, -4.0086],\n",
            "        [ 4.3116, -4.9786],\n",
            "        [ 3.7520, -4.9387],\n",
            "        [ 4.0806, -4.0960],\n",
            "        [-3.8803,  4.4120],\n",
            "        [-4.2428,  5.0436],\n",
            "        [ 4.9799, -5.5593],\n",
            "        [ 4.7716, -5.6234],\n",
            "        [-4.1002,  4.9420],\n",
            "        [-4.1974,  5.0146],\n",
            "        [ 4.5885, -5.2565],\n",
            "        [ 4.9343, -5.5822],\n",
            "        [ 2.6408, -2.8514],\n",
            "        [-4.0118,  4.7056],\n",
            "        [-3.7385,  4.2618],\n",
            "        [-3.9711,  4.6628],\n",
            "        [ 4.4309, -5.5432],\n",
            "        [ 1.8420, -2.6102],\n",
            "        [-4.0232,  4.7956],\n",
            "        [-3.9581,  4.6549],\n",
            "        [-3.7456,  4.1503]], device='cuda:0')\n",
            "tensor([[-4.1592,  4.9328],\n",
            "        [-4.0834,  4.8945],\n",
            "        [ 4.5133, -5.3162],\n",
            "        [ 1.6371, -2.2303],\n",
            "        [ 4.3926, -4.9568],\n",
            "        [ 4.7133, -5.6199],\n",
            "        [-3.7334,  4.1456],\n",
            "        [-4.0987,  4.9330],\n",
            "        [-4.0823,  4.8648],\n",
            "        [ 4.1190, -5.2461],\n",
            "        [ 4.7436, -5.5248],\n",
            "        [-4.1062,  4.9173],\n",
            "        [ 4.2298, -4.8746],\n",
            "        [ 4.6529, -5.3011],\n",
            "        [-4.0988,  4.8160],\n",
            "        [ 4.5277, -5.2553],\n",
            "        [-4.1557,  4.9505],\n",
            "        [-4.0126,  4.7095],\n",
            "        [-4.0998,  4.8806],\n",
            "        [-3.9109,  4.4524],\n",
            "        [-4.1960,  4.9798],\n",
            "        [ 4.0260, -4.9185],\n",
            "        [ 4.8831, -5.6885],\n",
            "        [ 4.1994, -4.9154],\n",
            "        [-3.9571,  4.6362],\n",
            "        [ 4.8355, -5.6535],\n",
            "        [-3.8136,  4.2787],\n",
            "        [ 4.2124, -4.9799],\n",
            "        [ 4.0486, -5.2866],\n",
            "        [ 4.6092, -5.5729],\n",
            "        [ 4.8323, -5.6755],\n",
            "        [ 4.5052, -5.3898]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Test:  97%|█████████▋| 31/32 [00:00<00:00, 46.32it/s]\u001b[A\n",
            "                                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.1873,  4.9770],\n",
            "        [-4.0982,  4.9308],\n",
            "        [ 2.3389, -2.9884],\n",
            "        [-3.8228,  4.3158],\n",
            "        [-4.0448,  4.9251],\n",
            "        [-3.1546,  3.2049],\n",
            "        [-4.0949,  4.8749],\n",
            "        [ 4.9885, -5.6180],\n",
            "        [ 4.9392, -5.4787],\n",
            "        [ 4.7963, -5.4521],\n",
            "        [ 4.4349, -5.5992],\n",
            "        [-3.9515,  4.6825],\n",
            "        [ 3.9181, -4.8738],\n",
            "        [-3.9988,  4.8013],\n",
            "        [-4.0401,  4.8476],\n",
            "        [ 4.6739, -5.1500],\n",
            "        [ 4.6261, -5.6483],\n",
            "        [ 3.1939, -3.3744],\n",
            "        [-4.0850,  4.7669],\n",
            "        [ 2.8369, -4.3089],\n",
            "        [-3.9528,  4.6123],\n",
            "        [-4.1775,  4.9780],\n",
            "        [-4.0702,  4.7894],\n",
            "        [-4.0812,  4.8773],\n",
            "        [ 4.5349, -5.3002],\n",
            "        [ 4.8646, -5.6602],\n",
            "        [-4.1922,  4.9993],\n",
            "        [ 2.9846, -3.4196],\n",
            "        [ 4.7996, -5.6620],\n",
            "        [ 4.3954, -5.2265],\n",
            "        [-4.0428,  4.6821],\n",
            "        [-4.0485,  4.8346]], device='cuda:0')\n",
            "tensor([[ 4.5744, -5.6004],\n",
            "        [ 4.5579, -5.3040],\n",
            "        [-4.1550,  4.9414],\n",
            "        [-3.5357,  3.6524],\n",
            "        [-4.1978,  5.0276],\n",
            "        [ 4.3693, -4.6853],\n",
            "        [ 3.6835, -4.1814],\n",
            "        [ 3.7562, -4.6524]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    ex0 = []\n",
        "    ex1 = []\n",
        "    for input_ids, attention_mask, token_type_ids, position_ids in tqdm(test_loader,\n",
        "                                                                        desc='Test',\n",
        "                                                                        position=1,\n",
        "                                                                        leave=None):\n",
        "\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        position_ids = position_ids.to(device)\n",
        "\n",
        "        # output = model(input_ids=input_ids,\n",
        "        #                attention_mask=attention_mask,\n",
        "        #                token_type_ids=token_type_ids,\n",
        "        #                position_ids=position_ids)\n",
        "        output = model(input_ids=input_ids,\n",
        "                      attention_mask=attention_mask,\n",
        "                      token_type_ids=token_type_ids,\n",
        "                      position_ids=position_ids)\n",
        "\n",
        "        logits = output.logits\n",
        "        print(logits)\n",
        "        batch_predictions = [0 if example[0] > example[1] else 1 for example in logits]\n",
        "        ex0 += [example[0].cpu().numpy() for example in logits]\n",
        "        ex1 += [example[1].cpu().numpy() for example in logits]\n",
        "        predictions += batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHcRJnJyR67L"
      },
      "outputs": [],
      "source": [
        "test_df['Category'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os3a8P4kR69R"
      },
      "outputs": [],
      "source": [
        "test_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['ex0'] = ex0\n",
        "test_df['ex1'] = ex1\n",
        "test_df.to_csv('bert_base_uncased.csv', index=False)"
      ],
      "metadata": {
        "id": "OOGp8W5mrdY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lowest_valid_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW2CZzq7rmVi",
        "outputId": "132fac43-fab1-4c5d-81b1-b636ee21db94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06016169534996152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(iter_x)\n",
        "print(acc_y)\n",
        "print(loss_y)\n",
        "print(max_iteration)\n",
        "iter_x_save = iter_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjHRVodHjtF8",
        "outputId": "be923f39-87ba-4e07-d0cd-97a81bd1bcb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[173, 346, 519, 692, 865, 1038, 1211, 1384, 1557, 1730, 173, 346, 519, 692, 865, 1038, 1211, 1384, 1557, 1730, 173, 346, 519, 692, 865, 1038, 1211, 1384, 1557, 1730]\n",
            "[0.98075, 0.98225, 0.981, 0.982, 0.981, 0.98075, 0.9805, 0.9815, 0.98125, 0.98025, 0.9795, 0.98125, 0.97875, 0.97875, 0.9805, 0.9795, 0.98025, 0.979, 0.9805, 0.9795, 0.979, 0.9795, 0.97825, 0.9805, 0.97875, 0.97925, 0.978, 0.97875, 0.9775, 0.98025]\n",
            "[0.0747612351551652, 0.06920943385921419, 0.0622002009768039, 0.07433835335541517, 0.0656944748479873, 0.07292660884559155, 0.07122827786952257, 0.0769701050594449, 0.06016169534996152, 0.07722926884889603, 0.08692536735907197, 0.07650979794561863, 0.0787965499330312, 0.08226688229478896, 0.08699593879282475, 0.08135075634345412, 0.06871987925842404, 0.08841130416840315, 0.08169422391802073, 0.08035016455687582, 0.10326784383505583, 0.09341150475665927, 0.10834171250462532, 0.08529962121974677, 0.08939112420193851, 0.07752046966925263, 0.0788073018193245, 0.09288919973187149, 0.0836608512327075, 0.07790071866475046]\n",
            "1731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "for i in range(len(iter_x)):\n",
        "    if cnt >= iter_x[i]:\n",
        "        iter_x[i] = max_iteration + iter_x[i]\n",
        "    cnt = iter_x[i]\n",
        "cnt = 0\n",
        "for i in range(len(iter_x)):\n",
        "    if cnt >= iter_x[i]:\n",
        "        iter_x[i] = max_iteration + iter_x[i]\n",
        "    cnt = iter_x[i]\n",
        "print(iter_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNscWEBSjtIc",
        "outputId": "3c86bfc2-7427-43fc-d5b0-3fbb83d07761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[173, 346, 519, 692, 865, 1038, 1211, 1384, 1557, 1730, 1904, 2077, 2250, 2423, 2596, 2769, 2942, 3115, 3288, 3461, 3635, 3808, 3981, 4154, 4327, 4500, 4673, 4846, 5019, 5192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (10, 3)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "x = iter_x\n",
        "y1 = acc_y\n",
        "y2 = loss_y\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.set_xlabel('iteration')\n",
        "ax1.set_ylabel('acc')\n",
        "ax1.plot(x, y1, color='green',label='acc')\n",
        "ax1.legend(loc='upper left')\n",
        "ax1.set_ylim([0.950,1])\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('valid_loss')\n",
        "ax2.plot(x, y2, color='deeppink',label='valid_loss')\n",
        "ax2.legend(loc='upper right')\n",
        "ax2.set_ylim([0.05,0.2])\n",
        "\n",
        "plt.title(\"bert-base-uncased\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "zjxBbLy6j7p1",
        "outputId": "fa04bcba-1f85-4a91-a2db-fbb2ad843e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(endtime - starttime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNk9eqtlj7sb",
        "outputId": "e6c04998-8e5d-43b3-fd22-f43fb0422bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2804.217930793762\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}